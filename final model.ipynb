{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0APBgJwdpQe"
   },
   "source": [
    "# IMPORT DATASETS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aHl3obUWx-Gw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns\n",
    "from tqdm import tqdm \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor, GradientBoostingRegressor , StackingRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error,  make_scorer\n",
    "from sklearn.model_selection import KFold,  cross_val_score,  RepeatedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, PowerTransformer,  StandardScaler\n",
    "from scipy.stats import kurtosis, skew\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "from xgboost import XGBRFRegressor, Booster\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from prettytable import PrettyTable \n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qWVDc3wx-Gw",
    "outputId": "a0049622-9bb8-4335-cf2e-e27b172e7bd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_ciLytQyx-Gx"
   },
   "outputs": [],
   "source": [
    "def r2_score_transform(train_pred, test_pred, train_label, test_label):\n",
    "\n",
    "  ''' \n",
    "  This function convert data into inverse yeo-johnson transformation and give a r2 score\n",
    "  Input - train and test predication array, train and test label\n",
    "  Output - inverse transform the array and compute the R2 score\n",
    "\n",
    "   '''\n",
    "  # Inverse transform the arrays\n",
    "  a, b    = pt.inverse_transform(train_pred.reshape(-1,1)), pt.inverse_transform(test_pred.reshape(-1,1))\n",
    "  x, y    = pt.inverse_transform(train_label.reshape(-1,1)), pt.inverse_transform(test_label.reshape(-1,1))\n",
    "   \n",
    "  # get r2 score of train and test data\n",
    "  train = r2_score(x,a)\n",
    "  test  = r2_score(y,b)\n",
    "    \n",
    "  return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "K1oj5Aw0x-Gy"
   },
   "outputs": [],
   "source": [
    "def kfold_grid_search(clf, params, train, label, fold, kfold, search = 'grid'):\n",
    "\n",
    "  ''' \n",
    "  This function compute the grid or random search cross validation and taken best estimator compute \n",
    "  R^2 score with kfold validation.\n",
    "  Input :\n",
    "    clf = model\n",
    "    params = dict of parameters for ranfom or grid search\n",
    "    train = train dataset\n",
    "    label = train data label\n",
    "    fold = grid or random cross validation folds\n",
    "    kfold = fold for kfold CV\n",
    "    search  = grid or random\n",
    "\n",
    "  '''\n",
    "\n",
    "  start = time.time()\n",
    "\n",
    "  # declare the grid search\n",
    "  if search == 'grid' :\n",
    "    clf_grid = GridSearchCV(estimator = clf,\n",
    "                        param_grid = params,\n",
    "                        n_jobs = -1,\n",
    "                        scoring = 'r2',\n",
    "                        cv = fold,\n",
    "                        verbose = 1)\n",
    "    # fit data into the grid model\n",
    "    clf_grid.fit(train, label)\n",
    "\n",
    "    # best estimator for the model\n",
    "    print('\\n')\n",
    "    print(f'Best Estimator : {clf_grid.best_estimator_}')\n",
    "    print('\\n')\n",
    "\n",
    "    # Model as best estimator\n",
    "    clf = clf_grid.best_estimator_\n",
    "    \n",
    "  # declre the random search \n",
    "  elif search == 'random' :\n",
    "    clf_grid = RandomizedSearchCV(estimator = clf,\n",
    "                        param_distributions = params,\n",
    "                        n_jobs = -1,\n",
    "                        scoring = 'r2',\n",
    "                        cv = fold,\n",
    "                        verbose = 1,\n",
    "                        )\n",
    "    # fit data into the grid model\n",
    "    clf_grid.fit(train, label)\n",
    "    \n",
    "    # best estimator for the model\n",
    "    print('\\n')\n",
    "    print(f'Best Estimator : {clf_grid.best_estimator_}')\n",
    "    print('\\n')\n",
    "    \n",
    "    # Model as best estimator\n",
    "    clf = clf_grid.best_estimator_\n",
    "\n",
    "  else:  \n",
    "    clf = clf\n",
    "\n",
    "\n",
    "  # genrate folds \n",
    "  kfold = KFold(n_splits= kfold, random_state= 42)\n",
    "\n",
    "  tr = [ ]\n",
    "  te = [ ]\n",
    "  i = 0\n",
    "  print('R2 metric : ')\n",
    "  for train_in, test_in in kfold.split(train):\n",
    "\n",
    "    # set indices of train and test data\n",
    "    xtrain, xtest = train.iloc[train_in], train.iloc[test_in]\n",
    "    ytrain, ytest = label[train_in], label[test_in]\n",
    "\n",
    "    # set best estimator as model\n",
    "    model = clf\n",
    "\n",
    "    # fit data into the best estimator\n",
    "    model.fit(xtrain, ytrain)\n",
    "    \n",
    "    # predict in train and test data\n",
    "    train_pred = model.predict(xtrain)\n",
    "    test_pred = model.predict(xtest)\n",
    "\n",
    "     # get r2 score of train and test data\n",
    "    tr_pre  = r2_score(ytrain, train_pred)\n",
    "    te_pre  = r2_score(ytest, test_pred)\n",
    "      \n",
    "    tr.append(tr_pre)\n",
    "    te.append(te_pre)\n",
    "\n",
    "    print(f'{i} r2 score of the train data {tr_pre} and test data {te_pre}')\n",
    "    \n",
    "    i += 1\n",
    "  \n",
    "  print(f'\\nAvg r2_score of train {np.mean(tr)} and test {np.mean(te)}')\n",
    "  \n",
    "\n",
    "  end = time.time()\n",
    "  print(f'Time taken - {(end-start)/60} min')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-pM6cVMHeuU"
   },
   "source": [
    "# Models with PCA + Synthetic and Binary features\n",
    "\n",
    "\n",
    "*   This datasets contain PCA (5) features, Binary features, label encoded features and created synthetic features.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "E_f18eTfc9Vn",
    "outputId": "9a0cd937-2a7d-4e55-e147-c5cac396a137"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>X24</th>\n",
       "      <th>X26</th>\n",
       "      <th>X27</th>\n",
       "      <th>X28</th>\n",
       "      <th>X29</th>\n",
       "      <th>X30</th>\n",
       "      <th>X31</th>\n",
       "      <th>X32</th>\n",
       "      <th>X33</th>\n",
       "      <th>X34</th>\n",
       "      <th>X35</th>\n",
       "      <th>X36</th>\n",
       "      <th>X37</th>\n",
       "      <th>X38</th>\n",
       "      <th>X39</th>\n",
       "      <th>X40</th>\n",
       "      <th>...</th>\n",
       "      <th>X371</th>\n",
       "      <th>X372</th>\n",
       "      <th>X373</th>\n",
       "      <th>X374</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "      <th>X0_label_encode</th>\n",
       "      <th>X1_label_encode</th>\n",
       "      <th>X2_label_encode</th>\n",
       "      <th>X3_label_encode</th>\n",
       "      <th>X4_label_encode</th>\n",
       "      <th>X5_label_encode</th>\n",
       "      <th>X6_label_encode</th>\n",
       "      <th>X8_label_encode</th>\n",
       "      <th>pca_feature0</th>\n",
       "      <th>pca_feature1</th>\n",
       "      <th>pca_feature2</th>\n",
       "      <th>pca_feature3</th>\n",
       "      <th>pca_feature4</th>\n",
       "      <th>X315_314_51_299</th>\n",
       "      <th>X299_300_301_271</th>\n",
       "      <th>X50_88_51_31</th>\n",
       "      <th>X46_263_119_261</th>\n",
       "      <th>X136_118_136_60</th>\n",
       "      <th>qua_encode_1</th>\n",
       "      <th>qua_encode_2</th>\n",
       "      <th>qua_encode_3</th>\n",
       "      <th>qua_encode_4</th>\n",
       "      <th>cos_encode_1</th>\n",
       "      <th>cos_encode_2</th>\n",
       "      <th>cos_encode_3</th>\n",
       "      <th>cos_encode_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>1.064804</td>\n",
       "      <td>-0.230379</td>\n",
       "      <td>27.062359</td>\n",
       "      <td>6.387048</td>\n",
       "      <td>2.354851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.901179</td>\n",
       "      <td>80.729628</td>\n",
       "      <td>14.457824</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>0.236773</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>0.307240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>0.979313</td>\n",
       "      <td>2.702576</td>\n",
       "      <td>31.020305</td>\n",
       "      <td>-0.160911</td>\n",
       "      <td>2.661553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.816796</td>\n",
       "      <td>7.221336</td>\n",
       "      <td>13.855619</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.091688</td>\n",
       "      <td>0.080591</td>\n",
       "      <td>0.091688</td>\n",
       "      <td>0.322075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>28.062189</td>\n",
       "      <td>21.291834</td>\n",
       "      <td>30.542186</td>\n",
       "      <td>0.322695</td>\n",
       "      <td>20.526222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>567.801379</td>\n",
       "      <td>9.717606</td>\n",
       "      <td>935.797419</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.376125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>27.972617</td>\n",
       "      <td>23.444034</td>\n",
       "      <td>25.805297</td>\n",
       "      <td>-5.440229</td>\n",
       "      <td>-11.833706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>674.842909</td>\n",
       "      <td>10.394944</td>\n",
       "      <td>930.330382</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.376125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>28.508003</td>\n",
       "      <td>22.819777</td>\n",
       "      <td>7.626386</td>\n",
       "      <td>13.286824</td>\n",
       "      <td>3.706443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>642.841100</td>\n",
       "      <td>250.973811</td>\n",
       "      <td>963.246231</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.376125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 404 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0 X1  ... cos_encode_1 cos_encode_2 cos_encode_3 cos_encode_4\n",
       "0   0  130.81   k  v  ...     0.096738     0.236773     0.096738     0.307240\n",
       "1   6   88.53   k  t  ...     0.091688     0.080591     0.091688     0.322075\n",
       "2   7   76.26  az  w  ...     0.001787     0.002932     0.001787     0.376125\n",
       "3   9   80.62  az  t  ...     0.001798     0.002470     0.001798     0.376125\n",
       "4  13   78.02  az  v  ...     0.001735     0.002592     0.001735     0.376125\n",
       "\n",
       "[5 rows x 404 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the train and test csv files \n",
    "\n",
    "train = pd.read_csv(r'/content/drive/MyDrive/Datasets/pca+feature_train.csv')\n",
    "test = pd.read_csv(r'/content/drive/MyDrive/Datasets/pca+feature_test.csv')\n",
    "\n",
    "train = train.drop(['Unnamed: 0'], axis = 1)\n",
    "test = test.drop(['Unnamed: 0'], axis = 1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlwSHydYH3Nl",
    "outputId": "8bcad5c3-f3ec-404c-f4aa-6659f9465d2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape -  (4209, 404)\n",
      "test data shape  -  (4209, 403)\n"
     ]
    }
   ],
   "source": [
    "#Check the Shape of the test and train data\n",
    "print('train data shape - ', train.shape)\n",
    "print('test data shape  - ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvufQCBkVXFc"
   },
   "outputs": [],
   "source": [
    "# declare the train set and label\n",
    "y2 = train.y\n",
    "x2 = train.iloc[:, 10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ns_ESoQXywpp",
    "outputId": "5b0f9c76-f9cd-4be3-c5d9-d1bf5e5ac103"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2820, 394) (2820,)\n",
      "(1389, 394) (1389,)\n"
     ]
    }
   ],
   "source": [
    "# Split train data into train-set and test-set\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2,y2, test_size = 0.33,random_state= 42)\n",
    "\n",
    "print(x_train2.shape, y_train2.shape)\n",
    "print(x_test2.shape, y_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAQPvhC8wojI"
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bkYGFq0obmNu",
    "outputId": "69725eef-3836-4067-90d7-7a0b3880a09c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Estimator : DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=8,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=10, splitter='best')\n",
      "\n",
      "\n",
      "R2 metric : \n",
      "0 r2 score of the train data 0.6813107472320485 and test data 0.5767082371099517\n",
      "1 r2 score of the train data 0.621586039510241 and test data 0.708513052109607\n",
      "2 r2 score of the train data 0.630831290790349 and test data 0.5631604647843083\n",
      "3 r2 score of the train data 0.6668606818390898 and test data 0.2787127830840411\n",
      "4 r2 score of the train data 0.6380355155912681 and test data 0.06995160992884453\n",
      "5 r2 score of the train data 0.6311910610649891 and test data 0.5245457377028628\n",
      "6 r2 score of the train data 0.63061835338783 and test data 0.6205419720909853\n",
      "7 r2 score of the train data 0.6221887781115217 and test data 0.6688339348247292\n",
      "8 r2 score of the train data 0.6419099223480337 and test data 0.46515590899698256\n",
      "9 r2 score of the train data 0.6279626162710936 and test data 0.5227980632203781\n",
      "10 r2 score of the train data 0.6308182124521897 and test data 0.4505968373538033\n",
      "11 r2 score of the train data 0.6259084033271662 and test data 0.5516506258243561\n",
      "12 r2 score of the train data 0.622938628458103 and test data 0.5444741383056872\n",
      "13 r2 score of the train data 0.6294581983558882 and test data 0.5987995140027604\n",
      "14 r2 score of the train data 0.6261923851524602 and test data 0.6724568866375927\n",
      "\n",
      "Avg r2_score of train 0.6351873889261516 and test 0.5211266510651261\n",
      "Time taken - 0.09999754031499226 min\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeRegressor()\n",
    "\n",
    "params = {'max_depth' : [2,3,4,8,10,15],\n",
    "          'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "          'random_state' : [5,10,20,30],\n",
    "          }\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, 10, kfold = 15, search= 'random') #(0.5780)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btI2P4xMRLco",
    "outputId": "d20a13c4-0ed8-44bf-91a0-3e6f7eac22ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.5734756571589295 data\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=3,\n",
    "                            max_features='auto',\n",
    "                            min_impurity_decrease=0.0,\n",
    "                            min_samples_leaf=1, min_samples_split=2,\n",
    "                            min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                            splitter='best')\n",
    "\n",
    "\n",
    "a = cross_val_score(dt, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15oXPTY-wsbd"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBNHDBtjbmNy",
    "outputId": "3054ea57-1867-43ff-f2b6-dff807d6118e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Estimator : RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=3, max_features=0.8, max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=1e-05,\n",
      "                      min_impurity_split=None, min_samples_leaf=5,\n",
      "                      min_samples_split=9, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=40, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "R2 metric : \n",
      "0 r2 score of the train data 0.5715153440871907 and test data 0.6075821902602618\n",
      "1 r2 score of the train data 0.5674883076551979 and test data 0.6511201254823615\n",
      "2 r2 score of the train data 0.5730553993723171 and test data 0.6021445241149124\n",
      "3 r2 score of the train data 0.60601763083342 and test data 0.30708047504635183\n",
      "4 r2 score of the train data 0.5773519833442724 and test data 0.5444356633636224\n",
      "5 r2 score of the train data 0.575621620235263 and test data 0.5670822703371299\n",
      "6 r2 score of the train data 0.5696064626862604 and test data 0.6596220214589319\n",
      "7 r2 score of the train data 0.5671942422662717 and test data 0.7064270195874032\n",
      "8 r2 score of the train data 0.5826081962660211 and test data 0.46894952095071496\n",
      "9 r2 score of the train data 0.5748447938417933 and test data 0.5578146764787673\n",
      "10 r2 score of the train data 0.5786768813257471 and test data 0.4979097062115938\n",
      "11 r2 score of the train data 0.5727663404360401 and test data 0.5977121928418523\n",
      "12 r2 score of the train data 0.569489839201403 and test data 0.6548764845232085\n",
      "13 r2 score of the train data 0.5702566085082328 and test data 0.6372309483627063\n",
      "14 r2 score of the train data 0.5687708169055417 and test data 0.6442986162389157\n",
      "\n",
      "Avg r2_score of train 0.5750176311309981 and test 0.5802857623505823\n",
      "Time taken - 3.083255358537038 min\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor()\n",
    "\n",
    "params = {'n_estimators':[40,50,60,70,100],\n",
    "             'max_depth':[3,5,6,7,8],\n",
    "             'min_samples_split':[2,3,4,5,6,7,8,9,10],\n",
    "             'max_features': [0.80,.95, 1.0],\n",
    "             'min_samples_leaf': [1, 2,3,4,5,6,7,8,9],\n",
    "             'min_impurity_decrease':[1e-5,1e-4,1e-3,1e-2,1e-1,0,1,10]}\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, fold = 10, kfold=15, search= 'random' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "feghQmUgRC8E",
    "outputId": "2c8177df-6922-4b89-badb-cdfd1cc1d98c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.5745664501511195 data\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=3, max_features=0.8, max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=1e-05,\n",
    "                      min_impurity_split=None, min_samples_leaf=5,\n",
    "                      min_samples_split=9, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=40, n_jobs=None, oob_score=False,\n",
    "                      random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "a = cross_val_score(rf, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMaVx3EOwv-O"
   },
   "source": [
    "### XGBoost-Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBhpmaLkbmN0",
    "outputId": "57b87e34-ed9d-4fcd-9b37-dfe494b37612"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Estimator : XGBRFRegressor(base_score=0.5, colsample_bylevel=1, colsample_bynode=0.8,\n",
      "               colsample_bytree=1, gamma=0, learning_rate=1, max_delta_step=0,\n",
      "               max_depth=15, max_features='log2', min_child_weight=1,\n",
      "               missing=None, n_estimators=100, n_jobs=1, nthread=None,\n",
      "               objective='reg:linear', random_state=5, reg_alpha=0,\n",
      "               reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
      "               subsample=0.8, verbosity=1)\n",
      "\n",
      "\n",
      "R2 metric : \n",
      "0 r2 score of the train data 0.5591106706797955 and test data 0.5969348853865986\n",
      "1 r2 score of the train data 0.5567761302990156 and test data 0.6392482807896993\n",
      "2 r2 score of the train data 0.5589944292139439 and test data 0.6035569639748404\n",
      "3 r2 score of the train data 0.5925375912978497 and test data 0.3071454665475717\n",
      "4 r2 score of the train data 0.5640973355720406 and test data 0.5338131420792587\n",
      "5 r2 score of the train data 0.5621640135494697 and test data 0.5595743834445313\n",
      "6 r2 score of the train data 0.5563947957633792 and test data 0.6555906505571116\n",
      "7 r2 score of the train data 0.553735574181428 and test data 0.7032605078583825\n",
      "8 r2 score of the train data 0.5690729048532857 and test data 0.4700063619141459\n",
      "9 r2 score of the train data 0.5620211189566908 and test data 0.5543351501847651\n",
      "10 r2 score of the train data 0.5666264217016058 and test data 0.48986189262393154\n",
      "11 r2 score of the train data 0.560688699269444 and test data 0.5770509865715794\n",
      "12 r2 score of the train data 0.5561268382448219 and test data 0.6574833593687027\n",
      "13 r2 score of the train data 0.5575377447394365 and test data 0.6320507247078625\n",
      "14 r2 score of the train data 0.5558804535718433 and test data 0.6482600205565894\n",
      "\n",
      "Avg r2_score of train 0.56211764812627 and test 0.5752115184377047\n",
      "Time taken - 4.294117295742035 min\n"
     ]
    }
   ],
   "source": [
    "clf = XGBRFRegressor(silent=True)\n",
    "\n",
    "xparams = {'learning_rate':[0.1,0.5,0.8,1],\n",
    "             'n_estimators':[70,80,100],\n",
    "             'max_depth':[2,3,4],\n",
    "             'colsample_bytree':[0.1,0.5,0.7,0.9,1],\n",
    "             'subsample':[0.2,0.3,0.5,1],\n",
    "             'gamma':[0.0001,0.001,0,0.1,0.01,0.5,1],\n",
    "             'reg_alpha':[0.00001,0.0001,0.001,0.01,0.1]}\n",
    "\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, fold = 10, kfold=15, search= 'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TO6MG_w_TTnm",
    "outputId": "530e5566-ad49-42e9-954d-8e28a065783a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.5718237374738755 data\n"
     ]
    }
   ],
   "source": [
    " xg = XGBRFRegressor(colsample_bylevel=1,\n",
    "               colsample_bynode=0.8, colsample_bytree=1, gamma=0,\n",
    "               learning_rate=1, max_delta_step=0, max_depth=5,\n",
    "               max_features=0.95, min_child_weight=1, min_impurity_decrease=1,\n",
    "               min_samples_leaf=1, min_samples_split=5, missing=None,\n",
    "               n_estimators=100, n_jobs=1, nthread=None, objective='reg:linear',\n",
    "               random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "               seed=None, silent=True, subsample=0.8, verbosity=1)\n",
    "\n",
    "a = cross_val_score(xg, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttqdxSQ0w9bu"
   },
   "source": [
    "AdaBoost-Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TNhfbyLzbmN6",
    "outputId": "79741445-ee76-46ee-f282-e7f55e38eeca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 13.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Estimator : AdaBoostRegressor(base_estimator=None, learning_rate=0.0001, loss='linear',\n",
      "                  n_estimators=100, random_state=10)\n",
      "\n",
      "\n",
      "R2 metric : \n",
      "0 r2 score of the train data 0.5720113699608151 and test data 0.6158808626834753\n",
      "1 r2 score of the train data 0.5619763801409192 and test data 0.6355339181615801\n",
      "2 r2 score of the train data 0.5707625343770122 and test data 0.606265905792721\n",
      "3 r2 score of the train data 0.6058312584998451 and test data 0.3073106403664668\n",
      "4 r2 score of the train data 0.5721886323759073 and test data 0.5351559426964696\n",
      "5 r2 score of the train data 0.5744676443771899 and test data 0.5623683551296568\n",
      "6 r2 score of the train data 0.5648681504239315 and test data 0.6552271007623669\n",
      "7 r2 score of the train data 0.5655959785551095 and test data 0.7061852214705656\n",
      "8 r2 score of the train data 0.580944156330872 and test data 0.4719427448074006\n",
      "9 r2 score of the train data 0.5714446221740298 and test data 0.5538494689733773\n",
      "10 r2 score of the train data 0.5756288720379016 and test data 0.49051296386692245\n",
      "11 r2 score of the train data 0.5737776034123998 and test data 0.5774840019937164\n",
      "12 r2 score of the train data 0.5684756314832162 and test data 0.6583991657352518\n",
      "13 r2 score of the train data 0.5664297487945196 and test data 0.6061219537121953\n",
      "14 r2 score of the train data 0.5647298013360682 and test data 0.6489853522620401\n",
      "\n",
      "Avg r2_score of train 0.5726088256186492 and test 0.5754149065609471\n",
      "Time taken - 15.350130430857341 min\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostRegressor()\n",
    "\n",
    "params = {'n_estimators'  : [100, 150, 200, ],\n",
    "          'learning_rate' :[0.0001,0.001,0.01, 0.1],\n",
    "          'loss' : [ 'linear', 'square', 'exponential'],\n",
    "          'random_state' : [10,20,30]\n",
    "          }\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, fold = 10, kfold = 15, search = 'random') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DDl3wtsRdwlV",
    "outputId": "1d2ad08f-3289-41a5-d378-7c461120b310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.5703529803771688 data\n"
     ]
    }
   ],
   "source": [
    " ab =  AdaBoostRegressor(base_estimator=None, learning_rate=0.0001, loss='linear',\n",
    "                  n_estimators=100, random_state=20)\n",
    "\n",
    "a = cross_val_score(ab, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqjOINHbxGGB"
   },
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LI05xzRdbmN9",
    "outputId": "615bca17-7b8c-475a-b9ac-350f64cb9c42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  7.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Estimator : GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.01, loss='huber',\n",
      "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=2000,\n",
      "                          n_iter_no_change=11, presort='deprecated',\n",
      "                          random_state=10, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "R2 metric : \n",
      "0 r2 score of the train data 0.5640270026713142 and test data 0.5844962160053929\n",
      "1 r2 score of the train data 0.5545558017178335 and test data 0.6263858956242915\n",
      "2 r2 score of the train data 0.5683858422857833 and test data 0.5882478867422942\n",
      "3 r2 score of the train data 0.6032325417831674 and test data 0.28827689355115715\n",
      "4 r2 score of the train data 0.5693710703909289 and test data 0.5268253421455653\n",
      "5 r2 score of the train data 0.5753977828991846 and test data 0.5509074520288433\n",
      "6 r2 score of the train data 0.5659724999522501 and test data 0.6529337483797\n",
      "7 r2 score of the train data 0.5692350047381489 and test data 0.7043729009907196\n",
      "8 r2 score of the train data 0.5827182335013722 and test data 0.4542972897883143\n",
      "9 r2 score of the train data 0.574540245256353 and test data 0.5319726953736295\n",
      "10 r2 score of the train data 0.5814156987703438 and test data 0.5028486395211187\n",
      "11 r2 score of the train data 0.5719466824608403 and test data 0.5601058443767275\n",
      "12 r2 score of the train data 0.56953918599406 and test data 0.6726943220669401\n",
      "13 r2 score of the train data 0.5654950604450828 and test data 0.6548945771237917\n",
      "14 r2 score of the train data 0.5668172693254028 and test data 0.6872046861726407\n",
      "\n",
      "Avg r2_score of train 0.572176661479471 and test 0.5724309593260751\n",
      "Time taken - 11.144120848178863 min\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingRegressor())\n",
    "\n",
    "params = {'n_estimators' : [800,1000, 1500, 2000, 2500],\n",
    "          'loss' : [ 'huber', 'exponential'],\n",
    "          'learning_rate' : [0.01, 0.01, 0.1],\n",
    "          'max_depth' : [3,4,5,7]\n",
    "          }\n",
    "\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, fold = 10, kfold = 15, search = 'random') #0.6900, 0.6677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZlxyx95mcxy",
    "outputId": "0e6fe817-8d67-466e-cecb-8c931f396b92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.5696356812530452 data\n"
     ]
    }
   ],
   "source": [
    "gb =  GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
    "                          init=None, learning_rate=0.01, loss='huber',\n",
    "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
    "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                          min_samples_leaf=1, min_samples_split=2,\n",
    "                          min_weight_fraction_leaf=0.0, n_estimators=2000,\n",
    "                          n_iter_no_change=11, presort='deprecated',\n",
    "                          random_state=10, subsample=1.0, tol=0.0001,\n",
    "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "\n",
    "a = cross_val_score(gb, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJq6ZibZxKGv"
   },
   "source": [
    "## LGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wcuvWmP4pUzr",
    "outputId": "550cc0d2-4f9d-4a43-ef7c-624106600b2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  8.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Estimator : LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "              importance_type='split', learning_rate=0.01, max_depth=3,\n",
      "              min_child_samples=50, min_child_weight=0.001, min_split_gain=0.0,\n",
      "              n_estimators=4000, n_jobs=-1, num_leaves=5, objective=None,\n",
      "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
      "\n",
      "\n",
      "R2 metric : \n",
      "0 r2 score of the train data 0.6539376054229651 and test data 0.5745765027557168\n",
      "1 r2 score of the train data 0.6479659676917198 and test data 0.6541898772014111\n",
      "2 r2 score of the train data 0.6553573129657073 and test data 0.5877012528118586\n",
      "3 r2 score of the train data 0.6804781717894042 and test data 0.2926826947679162\n",
      "4 r2 score of the train data 0.6577511726844416 and test data 0.5400561398326873\n",
      "5 r2 score of the train data 0.6563520755321524 and test data 0.5388823520975055\n",
      "6 r2 score of the train data 0.6502514789337726 and test data 0.6091735373791863\n",
      "7 r2 score of the train data 0.6476857317677991 and test data 0.6896003172617456\n",
      "8 r2 score of the train data 0.6622299194857179 and test data 0.47845027538518325\n",
      "9 r2 score of the train data 0.6614143575698203 and test data 0.5262909902666517\n",
      "10 r2 score of the train data 0.6610274429566736 and test data 0.5078239590939534\n",
      "11 r2 score of the train data 0.6547838989872861 and test data 0.5718646213126627\n",
      "12 r2 score of the train data 0.6524788377378758 and test data 0.6331363491047368\n",
      "13 r2 score of the train data 0.6494901652393692 and test data 0.6363914114588893\n",
      "14 r2 score of the train data 0.6552123606829265 and test data 0.6434023316558577\n",
      "\n",
      "Avg r2_score of train 0.656427766629842 and test 0.5656148408257309\n",
      "Time taken - 11.340572607517242 min\n"
     ]
    }
   ],
   "source": [
    "clf =  LGBMRegressor()\n",
    "\n",
    "params = {'min_child_samples' : [10, 20,50],\n",
    "          'num_leaves' : [5,6],\n",
    "          'max_depth' : [2, 3, 5],\n",
    "          'n_estimators' : [1000,2000,4000,5000],\n",
    "          'learning_rate' : [0.0001,0.001,0.01,0.1]\n",
    "          }\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2.ravel(), fold = 10, kfold = 15, search = 'random') #0.6920, 0.6622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kwQn8BuWpNsu",
    "outputId": "cf8f28f9-cc4b-4b7a-da44-ba92ff615c8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.5555207657145106 data\n"
     ]
    }
   ],
   "source": [
    "lb =  LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "              importance_type='split', learning_rate=0.01, max_depth=3,\n",
    "              min_child_samples=50, min_child_weight=0.001, min_split_gain=0.0,\n",
    "              n_estimators=5000, n_jobs=-1, num_leaves=5, objective=None,\n",
    "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
    "\n",
    "a = cross_val_score(lb, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AjOipx3Ai37v",
    "outputId": "aeda3282-b8e9-438e-fd88-dfa36d6c7c1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Score: 0.5762229576080763\n",
      "Standard Deviation: 0.08756604747415982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 12.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 12.2min finished\n"
     ]
    }
   ],
   "source": [
    "estimators = [ ('rf', RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=5, max_features=0.95, max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=0.001,\n",
    "                      min_impurity_split=None, min_samples_leaf=2,\n",
    "                      min_samples_split=8, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=70, n_jobs=None, oob_score=False,\n",
    "                      random_state=None, verbose=0, warm_start=False)),\n",
    "              \n",
    "                ('xg', XGBRFRegressor(colsample_bylevel=1,\n",
    "               colsample_bynode=0.8, colsample_bytree=1, gamma=0,\n",
    "               learning_rate=1, max_delta_step=0, max_depth=5,\n",
    "               max_features=0.95, min_child_weight=1, min_impurity_decrease=1,\n",
    "               min_samples_leaf=1, min_samples_split=5, missing=None,\n",
    "               n_estimators=100, n_jobs=1, nthread=None, objective='reg:linear',\n",
    "               random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "               seed=None, silent=True, subsample=0.8, verbosity=1)),\n",
    "              \n",
    "\n",
    "              ('gb', GradientBoostingRegressor(max_depth= 2, learning_rate= 0.1, random_state= 10,n_estimators=5000, \n",
    "                                n_iter_no_change = 11))\n",
    "              \n",
    "             ]\n",
    "\n",
    "stack = StackingRegressor(estimators= estimators,\n",
    "                          final_estimator= Ridge(), \n",
    "                          )\n",
    " \n",
    "cv_score = cross_val_score(stack, x2, y2.ravel(), scoring='r2', cv=10, verbose=5, n_jobs=-1)\n",
    "print('Mean Score:',cv_score.mean())\n",
    "print('Standard Deviation:',cv_score.std())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0N4J-PXLt228"
   },
   "source": [
    "## R^2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6rh--MqiiMF2",
    "outputId": "2318bce5-a869-43ef-898b-a7c40f9cf5c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------------------------------------+------------------+--------------+---------------+\n",
      "|       MODELS      |                   FEATURES                   | CROSS-VALIDATION | PUBLIC SCORE | PRIVATE SCORE |\n",
      "+-------------------+----------------------------------------------+------------------+--------------+---------------+\n",
      "|   DECISION TREE   | PCA(5) + BINARY + LABEL + SYNTHETIC FEATURES |      0.5211      |   0.55187    |    0.54823    |\n",
      "|   RANDOM FOREST   | PCA(5) + BINARY + LABEL + SYNTHETIC FEATURES |      0.5808      |   0.55327    |    0.54488    |\n",
      "|      XGBOOST      | PCA(5) + BINARY + LABEL + SYNTHETIC FEATURES |      0.5752      |   0.54654    |    0.54390    |\n",
      "|     ADA-BOOST     | PCA(5) + BINARY + LABEL + SYNTHETIC FEATURES |      0.5754      |   0.54911    |    0.54551    |\n",
      "| GRADIENT BOOSTING | PCA(5) + BINARY + LABEL + SYNTHETIC FEATURES |      0.5724      |   0.54427    |    0.53709    |\n",
      "|     LIGHT GBM     | PCA(5) + BINARY + LABEL + SYNTHETIC FEATURES |      0.5661      |   0.54420    |    0.52651    |\n",
      "|  STCKED-ENSEMBLE  | PCA(5) + BINARY + LABEL + SYNTHETIC FEATURES |      0.5762      |   0.55610    |    0.54816    |\n",
      "+-------------------+----------------------------------------------+------------------+--------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "col = ['MODELS', 'FEATURES', 'CROSS-VALIDATION' , 'PUBLIC SCORE', 'PRIVATE SCORE']\n",
    "\n",
    "tb = PrettyTable() \n",
    "\n",
    "tb.add_column(col[0], ['DECISION TREE', 'RANDOM FOREST', 'XGBOOST', 'ADA-BOOST', 'GRADIENT BOOSTING', 'LIGHT GBM', 'STCKED-ENSEMBLE'])\n",
    "\n",
    "tb.add_column(col[1], ['PCA(5) + BINARY + LABEL + SYNTHETIC FEATURES', 'PCA(5) + BINARY + LABEL + SYNTHETIC FEATURES','PCA(5) + BINARY + LABEL + SYNTHETIC FEATURES',\n",
    "                       'PCA(5) + BINARY + LABEL + SYNTHETIC FEATURES','PCA(5) + BINARY + LABEL + SYNTHETIC FEATURES','PCA(5) + BINARY + LABEL + SYNTHETIC FEATURES',\n",
    "                       'PCA(5) + BINARY + LABEL + SYNTHETIC FEATURES'])\n",
    "\n",
    "tb.add_column(col[2], ['0.5211', '0.5808', '0.5752', '0.5754', '0.5724', '0.5661', '0.5762'])\n",
    "\n",
    "tb.add_column(col[3], ['0.55187', '0.55327', '0.54654', '0.54911', '0.54427', '0.54420', '0.55610'])\n",
    "\n",
    "tb.add_column(col[4], ['0.54823', '0.54488', '0.54390', '0.54551', '0.53709', '0.52651', '0.54816'])\n",
    "\n",
    "print(tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-T04nllVlhzj"
   },
   "source": [
    "## OBSERVATION\n",
    "\n",
    "\n",
    "*   This data set created like using PCA method and synthetic features.\n",
    "\n",
    "*   Using PCA method created 5 features and created 22 synthetic features like difference between twi feature and ratio of another features.\n",
    "\n",
    "*   In these models use 10 k fold cross validation and grid or random search cross validation for the best parameters. \n",
    "\n",
    "*   We can see that above table random forest well performe in the cross validation and also good perform in kaggle public score. \n",
    "\n",
    "*   Stacked ensemble got higher score in public and private score.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Y7H_Cypv0dw"
   },
   "source": [
    "# Models with PCA + synthetic + Binary features and y target value clip 150sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "Vc0rztFxu6fC",
    "outputId": "4218b8b1-9f0d-45f1-aef7-f23294795b96"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X46_263_119_261</th>\n",
       "      <th>X136_118_136_60</th>\n",
       "      <th>qua_encode_1</th>\n",
       "      <th>qua_encode_2</th>\n",
       "      <th>qua_encode_3</th>\n",
       "      <th>qua_encode_4</th>\n",
       "      <th>cos_encode_1</th>\n",
       "      <th>cos_encode_2</th>\n",
       "      <th>cos_encode_3</th>\n",
       "      <th>cos_encode_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.901179</td>\n",
       "      <td>80.729628</td>\n",
       "      <td>14.457824</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>0.236773</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>0.307240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.816796</td>\n",
       "      <td>7.221336</td>\n",
       "      <td>13.855619</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.091688</td>\n",
       "      <td>0.080591</td>\n",
       "      <td>0.091688</td>\n",
       "      <td>0.322075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>567.801379</td>\n",
       "      <td>9.717606</td>\n",
       "      <td>935.797419</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.376125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>674.842909</td>\n",
       "      <td>10.394944</td>\n",
       "      <td>930.330382</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.376125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>642.841100</td>\n",
       "      <td>250.973811</td>\n",
       "      <td>963.246231</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.376125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 404 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0 X1  X2 X3 X4 X5 X6 X8  ...  X46_263_119_261  \\\n",
       "0   0  130.81   k  v  at  a  d  u  j  o  ...              1.0   \n",
       "1   6   88.53   k  t  av  e  d  y  l  o  ...              0.5   \n",
       "2   7   76.26  az  w   n  c  d  x  j  x  ...              1.0   \n",
       "3   9   80.62  az  t   n  f  d  x  l  e  ...              1.0   \n",
       "4  13   78.02  az  v   n  f  d  h  d  n  ...              1.0   \n",
       "\n",
       "   X136_118_136_60  qua_encode_1  qua_encode_2  qua_encode_3  qua_encode_4  \\\n",
       "0              1.0      6.901179     80.729628     14.457824           8.0   \n",
       "1              1.0     28.816796      7.221336     13.855619           8.0   \n",
       "2              0.0    567.801379      9.717606    935.797419           8.0   \n",
       "3              0.0    674.842909     10.394944    930.330382           8.0   \n",
       "4              0.0    642.841100    250.973811    963.246231           8.0   \n",
       "\n",
       "   cos_encode_1  cos_encode_2  cos_encode_3  cos_encode_4  \n",
       "0      0.096738      0.236773      0.096738      0.307240  \n",
       "1      0.091688      0.080591      0.091688      0.322075  \n",
       "2      0.001787      0.002932      0.001787      0.376125  \n",
       "3      0.001798      0.002470      0.001798      0.376125  \n",
       "4      0.001735      0.002592      0.001735      0.376125  \n",
       "\n",
       "[5 rows x 404 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the train and test csv files                                                      \n",
    "train = pd.read_csv('C:/Users/Dell/Python/Python/Python AAIC File/Assignments/CASE-STUDY ML/mercedes-benz-greener-manufacturing/Datasets/pca+feature_train.csv')\n",
    "test = pd.read_csv('C:/Users/Dell/Python/Python/Python AAIC File/Assignments/CASE-STUDY ML/mercedes-benz-greener-manufacturing/Datasets/pca+feature_test.csv')\n",
    "\n",
    "train = train.drop(['Unnamed: 0'], axis = 1)\n",
    "test = test.drop(['Unnamed: 0'], axis = 1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xUUJ_nYWwRP2",
    "outputId": "be486e54-4c16-4654-bb44-aa307afc9c71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape -  (4209, 404)\n",
      "test data shape  -  (4209, 403)\n"
     ]
    }
   ],
   "source": [
    "#Check the Shape of the test and train data\n",
    "print('train data shape - ', train.shape)\n",
    "print('test data shape  - ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "18zeMHTCN7dU"
   },
   "outputs": [],
   "source": [
    "# cilp the the y label at 150 which value have above 150\n",
    "train.loc[train['y'] > 150] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wzltji5jvp9G",
    "outputId": "93f7c2d0-20bd-496e-f18c-1a730f0c4b59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2820, 394) (2820,)\n",
      "(1389, 394) (1389,)\n"
     ]
    }
   ],
   "source": [
    "y2 = train.y\n",
    "x2 = train.iloc[:, 10:]\n",
    "\n",
    "# Split train data into train-set and test-set\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2,y2, test_size = 0.33,random_state= 42)\n",
    "\n",
    "print(x_train2.shape, y_train2.shape)\n",
    "print(x_test2.shape, y_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmApA4Z-wjaO"
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KRmO5DcIwjaP",
    "outputId": "be7beab1-9001-4122-eabc-e6dc2be73fbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    5.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Estimator : DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=3,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=5, splitter='best')\n",
      "\n",
      "\n",
      "R2 metric : \n",
      "0 r2 score of the train data 0.6480538816132388 and test data 0.6693714310012511\n",
      "1 r2 score of the train data 0.642465953902116 and test data 0.7702358085844839\n",
      "2 r2 score of the train data 0.6533336168366211 and test data 0.6034552624278658\n",
      "3 r2 score of the train data 0.650727064754295 and test data 0.626995114554626\n",
      "4 r2 score of the train data 0.6481815912325416 and test data 0.6753606349895027\n",
      "5 r2 score of the train data 0.6495238656607814 and test data 0.6594321202166429\n",
      "6 r2 score of the train data 0.6496479097970977 and test data 0.6594673475081894\n",
      "7 r2 score of the train data 0.6440153039529424 and test data 0.752330200943577\n",
      "8 r2 score of the train data 0.6627475307237207 and test data 0.4674067355568491\n",
      "9 r2 score of the train data 0.6516848915900538 and test data 0.6280380207465941\n",
      "10 r2 score of the train data 0.6597386061652126 and test data 0.5142825155435712\n",
      "11 r2 score of the train data 0.6504902324792055 and test data 0.6472108509331767\n",
      "12 r2 score of the train data 0.649356510657001 and test data 0.6486385218504416\n",
      "13 r2 score of the train data 0.6473059031423953 and test data 0.669704349641284\n",
      "14 r2 score of the train data 0.6490679486603913 and test data 0.6551988155854951\n",
      "\n",
      "Avg r2_score of train 0.6504227207445076 and test 0.6431418486722366\n",
      "Time taken - 0.11364267269770305 min\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=3,\n",
    "                            max_features='auto', max_leaf_nodes=None,\n",
    "                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                            min_samples_leaf=1, min_samples_split=2,\n",
    "                            min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                            random_state=None, splitter='best')\n",
    "\n",
    "params = {'max_depth' : [2,3,4,8,10,15],\n",
    "          'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "          'random_state' : [5,10,20,30],\n",
    "          }\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, 10, kfold = 15, search= 'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YPzgeJU5wjaR",
    "outputId": "eba21e0d-d306-4550-e9c0-69233af481d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.6355296996079519 data\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=3,\n",
    "                      max_features='auto', max_leaf_nodes=None,\n",
    "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                      min_samples_leaf=1, min_samples_split=2,\n",
    "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                      random_state=5, splitter='best')\n",
    "\n",
    "a = cross_val_score(dt, x2, y2, scoring= 'r2', cv= 5)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FGzDPKvziI5"
   },
   "source": [
    "## AdaBoost-Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09G1Z_klziI6",
    "outputId": "c348f937-299f-4194-975b-357ce1468b1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 14.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Estimator : AdaBoostRegressor(base_estimator=None, learning_rate=0.0001, loss='exponential',\n",
      "                  n_estimators=200, random_state=10)\n",
      "\n",
      "\n",
      "R2 metric : \n",
      "0 r2 score of the train data 0.6477109410342181 and test data 0.6667582180352138\n",
      "1 r2 score of the train data 0.6411183093664439 and test data 0.769834809588402\n",
      "2 r2 score of the train data 0.6519445325653355 and test data 0.6035245529110724\n",
      "3 r2 score of the train data 0.6501761962040864 and test data 0.6403407813302944\n",
      "4 r2 score of the train data 0.6467394871648264 and test data 0.6752756035497736\n",
      "5 r2 score of the train data 0.6482150084579972 and test data 0.6593962447784378\n",
      "6 r2 score of the train data 0.6483409079900484 and test data 0.6595427982210769\n",
      "7 r2 score of the train data 0.6427737983809947 and test data 0.7524045226988414\n",
      "8 r2 score of the train data 0.6612296144447891 and test data 0.4693381380158933\n",
      "9 r2 score of the train data 0.6503698925698844 and test data 0.6281263795271057\n",
      "10 r2 score of the train data 0.656219322638109 and test data 0.489240343280833\n",
      "11 r2 score of the train data 0.649137793025413 and test data 0.6470255138363956\n",
      "12 r2 score of the train data 0.6479060792497031 and test data 0.6619152500286267\n",
      "13 r2 score of the train data 0.6458712207158706 and test data 0.66957122946993\n",
      "14 r2 score of the train data 0.6476381814013082 and test data 0.6553517810957608\n",
      "\n",
      "Avg r2_score of train 0.6490260856806018 and test 0.6431764110911772\n",
      "Time taken - 18.583150271574656 min\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostRegressor(base_estimator=None, learning_rate=0.0001,\n",
    "                        n_estimators=300, random_state=None, loss= 'linear')\n",
    "\n",
    "params = {'n_estimators'  : [100, 150, 200, ],\n",
    "          'learning_rate' :[0.0001,0.001,0.01, 0.1],\n",
    "          'loss' : [ 'linear', 'square', 'exponential'],\n",
    "          'random_state' : [10,20,30]\n",
    "          }\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, fold = 10, kfold = 15, search = 'random') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EspY2HNlziI7",
    "outputId": "27d647dd-6a87-4636-cbc8-4c6a3dec9fa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.6424381050598855 data\n"
     ]
    }
   ],
   "source": [
    " ab =  AdaBoostRegressor(base_estimator=None, learning_rate=0.0001, loss='exponential',\n",
    "                  n_estimators=200, random_state=10)\n",
    "\n",
    "\n",
    "a = cross_val_score(ab, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RLHQNpMziI7"
   },
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_kh4iR5ziI7",
    "outputId": "e0f70f11-6217-4924-8b7e-e5ab288da2ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 16.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Estimator : GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.01, loss='huber',\n",
      "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                          n_iter_no_change=11, presort='deprecated',\n",
      "                          random_state=10, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "R2 metric : \n",
      "0 r2 score of the train data 0.6440326836974183 and test data 0.6493814982039965\n",
      "1 r2 score of the train data 0.6447564492798792 and test data 0.7714889267681285\n",
      "2 r2 score of the train data 0.6556808940577739 and test data 0.5873595530545905\n",
      "3 r2 score of the train data 0.6602751070405202 and test data 0.6296922521241193\n",
      "4 r2 score of the train data 0.6567517205050433 and test data 0.6810093083229571\n",
      "5 r2 score of the train data 0.6438252314922404 and test data 0.641228026796587\n",
      "6 r2 score of the train data 0.6528491710955487 and test data 0.6555477858191263\n",
      "7 r2 score of the train data 0.643880177692111 and test data 0.7560991766099738\n",
      "8 r2 score of the train data 0.6759464362526924 and test data 0.4576462792867908\n",
      "9 r2 score of the train data 0.6641764492261998 and test data 0.6133198511826266\n",
      "10 r2 score of the train data 0.6675695377306117 and test data 0.49966612497125706\n",
      "11 r2 score of the train data 0.6580900059344754 and test data 0.6316905816914543\n",
      "12 r2 score of the train data 0.6539165032379398 and test data 0.6742449715204522\n",
      "13 r2 score of the train data 0.6514083980245011 and test data 0.7091407057621535\n",
      "14 r2 score of the train data 0.6594997815908921 and test data 0.6877275468300248\n",
      "\n",
      "Avg r2_score of train 0.6555105697905231 and test 0.6430161725962826\n",
      "Time taken - 21.6081263701121 min\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
    "                          init=None, learning_rate=0.01, loss='huber',\n",
    "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
    "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                          min_samples_leaf=1, min_samples_split=2,\n",
    "                          min_weight_fraction_leaf=0.0, n_estimators=800,\n",
    "                          n_iter_no_change=11, presort='deprecated',\n",
    "                          random_state=10, subsample=1.0, tol=0.0001,\n",
    "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "\n",
    "params = {'n_estimators' : [500,800,1000, 1500, 2000],\n",
    "          'loss' : [ 'huber', 'exponential'],\n",
    "          'learning_rate' : [0.01, 0.01, 0.1],\n",
    "          'max_depth' : [3,4,5,7]\n",
    "          }\n",
    "\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, fold = 10, kfold = 15, search = 'random') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMsX8KBCziI8",
    "outputId": "fbc37fc6-4fcd-414a-c834-9b850b989fe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.640877235785154 data\n"
     ]
    }
   ],
   "source": [
    "gb =  GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
    "                          init=None, learning_rate=0.01, loss='huber',\n",
    "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
    "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                          min_samples_leaf=1, min_samples_split=2,\n",
    "                          min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
    "                          n_iter_no_change=11, presort='deprecated',\n",
    "                          random_state=10, subsample=1.0, tol=0.0001,\n",
    "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "\n",
    "a = cross_val_score(gb, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTPW_kwQx-Gu"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dFQ5QhM0x-Gv",
    "outputId": "1bc5cb0f-eb1f-403f-f28b-3548e3525362"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Estimator : RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=6, max_features=1.0, max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.1,\n",
      "                      min_impurity_split=None, min_samples_leaf=6,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=70, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "R2 metric : \n",
      "0 r2 score of the train data 0.6761806107128834 and test data 0.6573744354284433\n",
      "1 r2 score of the train data 0.6690398809859387 and test data 0.7684369053571742\n",
      "2 r2 score of the train data 0.6804516359221022 and test data 0.5979577019930118\n",
      "3 r2 score of the train data 0.6738827442338753 and test data 0.6428903435953389\n",
      "4 r2 score of the train data 0.6723676756508512 and test data 0.6868064575030692\n",
      "5 r2 score of the train data 0.6752737867274246 and test data 0.6627912033311976\n",
      "6 r2 score of the train data 0.6748901863798457 and test data 0.6620421469359128\n",
      "7 r2 score of the train data 0.670449835669485 and test data 0.7515754444268572\n",
      "8 r2 score of the train data 0.6894411286450259 and test data 0.47322601756498917\n",
      "9 r2 score of the train data 0.6776469544688636 and test data 0.6343698165475739\n",
      "10 r2 score of the train data 0.6835132636421446 and test data 0.516588880256428\n",
      "11 r2 score of the train data 0.676175147732486 and test data 0.6506305811277528\n",
      "12 r2 score of the train data 0.673793912539155 and test data 0.6604770020924078\n",
      "13 r2 score of the train data 0.6715570812360592 and test data 0.705112780339884\n",
      "14 r2 score of the train data 0.6744616810048314 and test data 0.6628970220046523\n",
      "\n",
      "Avg r2_score of train 0.6759417017033982 and test 0.648878449233646\n",
      "Time taken - 4.554728877544403 min\n"
     ]
    }
   ],
   "source": [
    "clf =  RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=5, max_features=0.95, max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=0.001,\n",
    "                      min_impurity_split=None, min_samples_leaf=2,\n",
    "                      min_samples_split=8, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=70, n_jobs=None, oob_score=False,\n",
    "                      random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "params = {'n_estimators':[40,50,60,70,100],\n",
    "             'max_depth':[3,5,6,7,8],\n",
    "             'min_samples_split':[2,3,4,5,6,7,8,9,10],\n",
    "             'max_features': [0.80,.95, 1.0],\n",
    "             'min_samples_leaf': [1, 2,3,4,5,6,7,8,9],\n",
    "             'min_impurity_decrease':[1e-5,1e-4,1e-3,1e-2,1e-1,0,1,10]}\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, fold = 10, kfold=15, search= 'random' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4hNKr9ux-Gv",
    "outputId": "3cf94f14-5e82-48ce-ed0d-2a709827b048"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.6457039283917678 data\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=6, max_features=1.0, max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=0.1,\n",
    "                      min_impurity_split=None, min_samples_leaf=6,\n",
    "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=700, n_jobs=None, oob_score=False,\n",
    "                      random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "a = cross_val_score(rf, x2, y_trans, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6JU-cQt7gUH"
   },
   "source": [
    "## LGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2wQHiBU6ziI9",
    "outputId": "03355b00-caec-4fc4-fbd9-aaac85963030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  8.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Estimator : LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "              importance_type='split', learning_rate=0.001, max_depth=3,\n",
      "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "              n_estimators=5000, n_jobs=-1, num_leaves=6, objective=None,\n",
      "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
      "\n",
      "\n",
      "R2 metric : \n",
      "0 r2 score of the train data 0.6646104803919637 and test data 0.6630022586838633\n",
      "1 r2 score of the train data 0.6583630541223624 and test data 0.7675817081799015\n",
      "2 r2 score of the train data 0.6690928334118285 and test data 0.6058607904596616\n",
      "3 r2 score of the train data 0.6649248016084909 and test data 0.6436142891192629\n",
      "4 r2 score of the train data 0.6624097369466116 and test data 0.6936298300139243\n",
      "5 r2 score of the train data 0.6646374197084737 and test data 0.665528759256929\n",
      "6 r2 score of the train data 0.6650009587077517 and test data 0.6631473971131017\n",
      "7 r2 score of the train data 0.6604176474827126 and test data 0.7501455280855138\n",
      "8 r2 score of the train data 0.6798367687788365 and test data 0.47817342733889345\n",
      "9 r2 score of the train data 0.666810659145471 and test data 0.6324631406650509\n",
      "10 r2 score of the train data 0.6751084633746813 and test data 0.5094524762619161\n",
      "11 r2 score of the train data 0.6656215129264706 and test data 0.6408139966621724\n",
      "12 r2 score of the train data 0.6642275397074902 and test data 0.6602457548831437\n",
      "13 r2 score of the train data 0.6622259856150257 and test data 0.7103376271877867\n",
      "14 r2 score of the train data 0.6632183999773167 and test data 0.6660837115764423\n",
      "\n",
      "Avg r2_score of train 0.6657670841270324 and test 0.650005379699171\n",
      "Time taken - 13.400730057557423 min\n"
     ]
    }
   ],
   "source": [
    "clf =  LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "              importance_type='split', learning_rate=0.01, max_depth=5,\n",
    "              min_child_samples=50, min_child_weight=0.001, min_split_gain=0.0,\n",
    "              n_estimators=1000, n_jobs=-1, num_leaves=5, objective=None,\n",
    "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
    "\n",
    "params = {'min_child_samples' : [10, 20,50],\n",
    "          'num_leaves' : [5,6],\n",
    "          'max_depth' : [2, 3, 5],\n",
    "          'n_estimators' : [1000,2000,4000,5000],\n",
    "          'learning_rate' : [0.0001,0.001,0.01,0.1]\n",
    "          }\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2.ravel(), fold = 10, kfold = 15, search = 'random') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ljawg1gsziI9",
    "outputId": "82cfc3a9-507f-41e1-cdbb-9147c98378ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.6468964578401072 data\n"
     ]
    }
   ],
   "source": [
    "lb =  LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "              importance_type='split', learning_rate=0.001, max_depth=3,\n",
    "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
    "              n_estimators=5000, n_jobs=-1, num_leaves=6, objective=None,\n",
    "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
    "\n",
    "a = cross_val_score(lb, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLRXtJuKzS8f"
   },
   "source": [
    "### XGBoost-Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VdVNDRm0zS8h",
    "outputId": "794dbec8-7aa2-4a79-8ee7-4d90d0a52791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 metric : \n",
      "0 r2 score of the train data 0.6066547132057518 and test data 0.63525224317498\n",
      "1 r2 score of the train data 0.6034804178965002 and test data 0.6963600576690997\n",
      "2 r2 score of the train data 0.6105771133880324 and test data 0.601203463972948\n",
      "3 r2 score of the train data 0.6128226383721311 and test data 0.5564458465086671\n",
      "4 r2 score of the train data 0.6111184302393099 and test data 0.5830068184166133\n",
      "5 r2 score of the train data 0.6082304797363157 and test data 0.6281456387239466\n",
      "6 r2 score of the train data 0.6089669154327122 and test data 0.6561857533878476\n",
      "7 r2 score of the train data 0.6035336362444628 and test data 0.7099815395322746\n",
      "8 r2 score of the train data 0.6238022287495313 and test data 0.4687577983273177\n",
      "9 r2 score of the train data 0.6125290949699321 and test data 0.5628813136358713\n",
      "10 r2 score of the train data 0.6200341125828022 and test data 0.48810031559351164\n",
      "11 r2 score of the train data 0.6088743143552269 and test data 0.6168210561799822\n",
      "12 r2 score of the train data 0.6083074897370442 and test data 0.658639519541895\n",
      "13 r2 score of the train data 0.6073444564835199 and test data 0.6416319396499979\n",
      "14 r2 score of the train data 0.607225555256518 and test data 0.6514214996312307\n",
      "\n",
      "Avg r2_score of train 0.6102334397766528 and test 0.6103223202630789\n",
      "Time taken - 0.7519578218460083 min\n"
     ]
    }
   ],
   "source": [
    "clf = XGBRFRegressor(colsample_bylevel=1,colsample_bynode=0.8, colsample_bytree=1, gamma=0,\n",
    "               learning_rate=1, max_delta_step=0, max_depth=5,\n",
    "               max_features=0.95, min_child_weight=1, min_impurity_decrease=1,\n",
    "               min_samples_leaf=1, min_samples_split=5, missing=None,\n",
    "               n_estimators=100, n_jobs=1, nthread=None, objective='reg:linear',\n",
    "               random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "               seed=None, silent=True, subsample=0.8, verbosity=1)\n",
    "\n",
    "xparams = {'learning_rate':[0.1,0.5,0.8,1],\n",
    "             'n_estimators':[70,80,100],\n",
    "             'max_depth':[2,3,4],\n",
    "             'colsample_bytree':[0.1,0.5,0.7,0.9,1],\n",
    "             'subsample':[0.2,0.3,0.5,1],\n",
    "             'gamma':[0.0001,0.001,0,0.1,0.01,0.5,1],\n",
    "             'reg_alpha':[0.00001,0.0001,0.001,0.01,0.1]}\n",
    "\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, fold = 10, kfold=15, search= False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IHt45xeCzS8h",
    "outputId": "f6d9c600-3eb3-4c82-a050-e48787ee4e0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.6084653791278974 data\n"
     ]
    }
   ],
   "source": [
    " xg = XGBRFRegressor(colsample_bylevel=1,\n",
    "               colsample_bynode=0.8, colsample_bytree=1, gamma=0,\n",
    "               learning_rate=1, max_delta_step=0, max_depth=5,\n",
    "               max_features=0.95, min_child_weight=1, min_impurity_decrease=1,\n",
    "               min_samples_leaf=1, min_samples_split=5, missing=None,\n",
    "               n_estimators=100, n_jobs=1, nthread=None, objective='reg:linear',\n",
    "               random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "               seed=None, silent=True, subsample=0.8, verbosity=1)\n",
    "\n",
    "a = cross_val_score(xg, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_17e2aSDUyp"
   },
   "source": [
    "## Stack ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WdrwrTnEjPIU"
   },
   "outputs": [],
   "source": [
    "estimators = [ ('rf', RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=5, max_features=0.95, max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=0.001,\n",
    "                      min_impurity_split=None, min_samples_leaf=2,\n",
    "                      min_samples_split=8, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=70, n_jobs=None, oob_score=False,\n",
    "                      random_state=None, verbose=0, warm_start=False)),\n",
    "              \n",
    "                ('xg', XGBRFRegressor(colsample_bylevel=1,\n",
    "               colsample_bynode=0.8, colsample_bytree=1, gamma=0,\n",
    "               learning_rate=1, max_delta_step=0, max_depth=5,\n",
    "               max_features=0.95, min_child_weight=1, min_impurity_decrease=1,\n",
    "               min_samples_leaf=1, min_samples_split=5, missing=None,\n",
    "               n_estimators=100, n_jobs=1, nthread=None, objective='reg:linear',\n",
    "               random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "               seed=None, silent=True, subsample=0.8, verbosity=0)),\n",
    "              \n",
    "\n",
    "              ('lg', LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "              importance_type='split', learning_rate=0.001, max_depth=3,\n",
    "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
    "              n_estimators=5000, n_jobs=-1, num_leaves=6, objective=None,\n",
    "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0))\n",
    "              \n",
    "             ]\n",
    "\n",
    "stack = StackingRegressor(estimators= estimators,\n",
    "                          final_estimator= Ridge(), \n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6CDAdAgJegUo",
    "outputId": "497132ad-454d-4c88-af10-f39d6fcfd182"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Score: 0.6412507934357022\n",
      "Standard Deviation: 0.030613234929429335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 22.7min finished\n"
     ]
    }
   ],
   "source": [
    "cv_score = cross_val_score(stack, x2, y2.ravel(), scoring='r2', cv= 5, verbose=5, n_jobs=-1)\n",
    "print('Mean Score:',cv_score.mean())\n",
    "print('Standard Deviation:',cv_score.std())   #0.6404, 0.64200,  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzq6OnQCnMT3"
   },
   "source": [
    "## R^2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o-qW_MOB_fVD",
    "outputId": "6d29d5da-6782-43b6-c8d4-eb2478ad55ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------------------------------------------------+------------------+--------------+---------------+\n",
      "|       MODELS      |                         FEATURES                         | CROSS-VALIDATION | PUBLIC SCORE | PRIVATE SCORE |\n",
      "+-------------------+----------------------------------------------------------+------------------+--------------+---------------+\n",
      "|   DECISION TREE   | PCA(5) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES |      0.6451      |   0.53938    |    0.53968    |\n",
      "|   RANDOM FOREST   | PCA(5) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES |      0.6488      |   0.55102    |    0.54857    |\n",
      "|      XGBOOST      | PCA(5) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES |      0.6102      |   0.54616    |    0.53822    |\n",
      "|     ADA-BOOST     | PCA(5) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES |      0.6431      |   0.53998    |    0.53963    |\n",
      "| GRADIENT BOOSTING | PCA(5) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES |      0.6430      |   0.54294    |    0.53637    |\n",
      "|     LIGHT GBM     | PCA(5) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES |      0.6500      |   0.55541    |    0.54895    |\n",
      "|  STCKED-ENSEMBLE  | PCA(5) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES |      0.6412      |   0.55514    |    0.54951    |\n",
      "+-------------------+----------------------------------------------------------+------------------+--------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "col = ['MODELS', 'FEATURES', 'CROSS-VALIDATION' , 'PUBLIC SCORE', 'PRIVATE SCORE']\n",
    "\n",
    "tb = PrettyTable() \n",
    "\n",
    "tb.add_column(col[0], ['DECISION TREE', 'RANDOM FOREST', 'XGBOOST', 'ADA-BOOST', 'GRADIENT BOOSTING', 'LIGHT GBM', 'STCKED-ENSEMBLE'])\n",
    "\n",
    "tb.add_column(col[1], ['PCA(5) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES','PCA(5) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES',\n",
    "                       'PCA(5) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES','PCA(5) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES',\n",
    "                       'PCA(5) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES','PCA(5) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES',\n",
    "                       'PCA(5) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES',])\n",
    "\n",
    "tb.add_column(col[2], ['0.6451', '0.6488', '0.6102', '0.6431', '0.6430', '0.6500', '0.6412'])\n",
    "\n",
    "tb.add_column(col[3], ['0.53938', '0.55102', '0.54616', '0.53998', '0.54294', '0.55541', '0.55514'])\n",
    "\n",
    "tb.add_column(col[4], ['0.53968', '0.54857', '0.53822', '0.53963', '0.53637', '0.54895', '0.54951'])\n",
    "\n",
    "print(tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xko4eqmHnRKi"
   },
   "source": [
    "## OBSERVATION \n",
    "\n",
    "\n",
    "*   This dataset contain 5 PCA feature, binary features, label encoded features and synthetic featues.\n",
    "\n",
    "*   This dataset with some experiment found that when we clip our y target with threshold 150secs then we got good score.\n",
    "\n",
    "*   We got good score in this data higher than another datasets, we see that in above table stacked ensemble get best score in public 0.55514 and private 0.54951 score.\n",
    "\n",
    "*   All models well perform in cross validation sets with k fold method.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1kw42YcDaFd"
   },
   "source": [
    "# Model with important feature of models (synethic features + 100 PCA + Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "g0lNkVS1Dlu0",
    "outputId": "c1692bdb-d840-4484-b6f5-30e9739563bf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>X27</th>\n",
       "      <th>X28</th>\n",
       "      <th>X29</th>\n",
       "      <th>X31</th>\n",
       "      <th>X32</th>\n",
       "      <th>X35</th>\n",
       "      <th>X37</th>\n",
       "      <th>X38</th>\n",
       "      <th>X41</th>\n",
       "      <th>X43</th>\n",
       "      <th>X44</th>\n",
       "      <th>X45</th>\n",
       "      <th>X46</th>\n",
       "      <th>X47</th>\n",
       "      <th>X48</th>\n",
       "      <th>X49</th>\n",
       "      <th>X50</th>\n",
       "      <th>X51</th>\n",
       "      <th>X52</th>\n",
       "      <th>X54</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X61</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_feature74</th>\n",
       "      <th>pca_feature75</th>\n",
       "      <th>pca_feature76</th>\n",
       "      <th>pca_feature77</th>\n",
       "      <th>pca_feature78</th>\n",
       "      <th>pca_feature79</th>\n",
       "      <th>pca_feature80</th>\n",
       "      <th>pca_feature81</th>\n",
       "      <th>pca_feature82</th>\n",
       "      <th>pca_feature83</th>\n",
       "      <th>pca_feature84</th>\n",
       "      <th>pca_feature85</th>\n",
       "      <th>pca_feature86</th>\n",
       "      <th>pca_feature87</th>\n",
       "      <th>pca_feature88</th>\n",
       "      <th>pca_feature89</th>\n",
       "      <th>pca_feature90</th>\n",
       "      <th>pca_feature91</th>\n",
       "      <th>pca_feature92</th>\n",
       "      <th>pca_feature93</th>\n",
       "      <th>pca_feature94</th>\n",
       "      <th>pca_feature95</th>\n",
       "      <th>pca_feature96</th>\n",
       "      <th>pca_feature97</th>\n",
       "      <th>pca_feature98</th>\n",
       "      <th>pca_feature99</th>\n",
       "      <th>X315_314_51_340</th>\n",
       "      <th>X299_300_301_328</th>\n",
       "      <th>X50_100_51_31</th>\n",
       "      <th>X46_263_118_261</th>\n",
       "      <th>X136_118_136_355</th>\n",
       "      <th>qua_encode_1</th>\n",
       "      <th>qua_encode_2</th>\n",
       "      <th>qua_encode_3</th>\n",
       "      <th>qua_encode_4</th>\n",
       "      <th>cos_encode_1</th>\n",
       "      <th>cos_encode_2</th>\n",
       "      <th>cos_encode_3</th>\n",
       "      <th>cos_encode_4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.478423</td>\n",
       "      <td>-0.041581</td>\n",
       "      <td>-0.364478</td>\n",
       "      <td>-0.001854</td>\n",
       "      <td>-0.041399</td>\n",
       "      <td>0.309832</td>\n",
       "      <td>0.177070</td>\n",
       "      <td>0.251996</td>\n",
       "      <td>-0.036021</td>\n",
       "      <td>0.635873</td>\n",
       "      <td>-0.171752</td>\n",
       "      <td>-0.129971</td>\n",
       "      <td>0.459947</td>\n",
       "      <td>0.029937</td>\n",
       "      <td>0.123607</td>\n",
       "      <td>-0.564660</td>\n",
       "      <td>-0.216277</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.308547</td>\n",
       "      <td>-0.172807</td>\n",
       "      <td>0.095357</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>-0.041449</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>-0.084739</td>\n",
       "      <td>-0.078419</td>\n",
       "      <td>0.340805</td>\n",
       "      <td>1.524459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.506038</td>\n",
       "      <td>2.181611</td>\n",
       "      <td>2.181611</td>\n",
       "      <td>3.024459</td>\n",
       "      <td>3.024459</td>\n",
       "      <td>0.282399</td>\n",
       "      <td>0.396161</td>\n",
       "      <td>0.050612</td>\n",
       "      <td>0.268648</td>\n",
       "      <td>130.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043473</td>\n",
       "      <td>0.101824</td>\n",
       "      <td>0.219871</td>\n",
       "      <td>-0.067341</td>\n",
       "      <td>-0.223638</td>\n",
       "      <td>-0.003935</td>\n",
       "      <td>-0.010555</td>\n",
       "      <td>-0.035781</td>\n",
       "      <td>0.408114</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>-0.258432</td>\n",
       "      <td>-0.093938</td>\n",
       "      <td>-0.306398</td>\n",
       "      <td>-0.075213</td>\n",
       "      <td>0.265231</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.123904</td>\n",
       "      <td>0.272324</td>\n",
       "      <td>-0.112198</td>\n",
       "      <td>0.102860</td>\n",
       "      <td>-0.181315</td>\n",
       "      <td>-0.064247</td>\n",
       "      <td>0.015819</td>\n",
       "      <td>-0.082439</td>\n",
       "      <td>-0.076255</td>\n",
       "      <td>-0.312864</td>\n",
       "      <td>-0.178265</td>\n",
       "      <td>0.810873</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.402006</td>\n",
       "      <td>1.143471</td>\n",
       "      <td>0.786942</td>\n",
       "      <td>2.310873</td>\n",
       "      <td>2.977540</td>\n",
       "      <td>0.193438</td>\n",
       "      <td>0.460063</td>\n",
       "      <td>0.157992</td>\n",
       "      <td>0.381311</td>\n",
       "      <td>88.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256844</td>\n",
       "      <td>0.525369</td>\n",
       "      <td>0.039997</td>\n",
       "      <td>0.151710</td>\n",
       "      <td>0.104512</td>\n",
       "      <td>0.331503</td>\n",
       "      <td>-0.499652</td>\n",
       "      <td>-0.475288</td>\n",
       "      <td>-0.127968</td>\n",
       "      <td>0.362647</td>\n",
       "      <td>-0.099530</td>\n",
       "      <td>0.276298</td>\n",
       "      <td>-0.340234</td>\n",
       "      <td>-0.194046</td>\n",
       "      <td>-0.097575</td>\n",
       "      <td>0.358764</td>\n",
       "      <td>-0.071983</td>\n",
       "      <td>-0.431886</td>\n",
       "      <td>-0.301564</td>\n",
       "      <td>-0.238250</td>\n",
       "      <td>0.078197</td>\n",
       "      <td>0.372351</td>\n",
       "      <td>-0.350833</td>\n",
       "      <td>0.282364</td>\n",
       "      <td>1.032828</td>\n",
       "      <td>0.060364</td>\n",
       "      <td>1.902455</td>\n",
       "      <td>0.786635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791880</td>\n",
       "      <td>0.090326</td>\n",
       "      <td>5.304909</td>\n",
       "      <td>9.109818</td>\n",
       "      <td>2.286635</td>\n",
       "      <td>3.073269</td>\n",
       "      <td>0.615764</td>\n",
       "      <td>0.205873</td>\n",
       "      <td>0.185820</td>\n",
       "      <td>0.013910</td>\n",
       "      <td>76.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026078</td>\n",
       "      <td>-0.088235</td>\n",
       "      <td>-0.227881</td>\n",
       "      <td>0.049265</td>\n",
       "      <td>-0.096558</td>\n",
       "      <td>0.515847</td>\n",
       "      <td>-0.261283</td>\n",
       "      <td>-0.269399</td>\n",
       "      <td>-0.039287</td>\n",
       "      <td>0.137951</td>\n",
       "      <td>0.136733</td>\n",
       "      <td>-0.247255</td>\n",
       "      <td>0.333867</td>\n",
       "      <td>0.048052</td>\n",
       "      <td>-0.315151</td>\n",
       "      <td>-0.162288</td>\n",
       "      <td>-0.026982</td>\n",
       "      <td>-0.007258</td>\n",
       "      <td>-0.010178</td>\n",
       "      <td>-0.174021</td>\n",
       "      <td>0.071059</td>\n",
       "      <td>0.108900</td>\n",
       "      <td>0.052355</td>\n",
       "      <td>0.308304</td>\n",
       "      <td>0.040069</td>\n",
       "      <td>-0.112119</td>\n",
       "      <td>3.725739</td>\n",
       "      <td>1.054499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.788393</td>\n",
       "      <td>-0.281703</td>\n",
       "      <td>8.951479</td>\n",
       "      <td>8.951479</td>\n",
       "      <td>2.554499</td>\n",
       "      <td>3.608998</td>\n",
       "      <td>0.866039</td>\n",
       "      <td>0.118635</td>\n",
       "      <td>0.130835</td>\n",
       "      <td>0.075874</td>\n",
       "      <td>80.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124707</td>\n",
       "      <td>-0.199144</td>\n",
       "      <td>-0.051635</td>\n",
       "      <td>0.184691</td>\n",
       "      <td>0.038281</td>\n",
       "      <td>0.095479</td>\n",
       "      <td>-0.001220</td>\n",
       "      <td>-0.179807</td>\n",
       "      <td>-0.174086</td>\n",
       "      <td>0.135042</td>\n",
       "      <td>0.062843</td>\n",
       "      <td>-0.018008</td>\n",
       "      <td>0.267680</td>\n",
       "      <td>0.038113</td>\n",
       "      <td>0.112184</td>\n",
       "      <td>0.020562</td>\n",
       "      <td>-0.040897</td>\n",
       "      <td>-0.024733</td>\n",
       "      <td>-0.276257</td>\n",
       "      <td>-0.162307</td>\n",
       "      <td>0.024471</td>\n",
       "      <td>0.043678</td>\n",
       "      <td>-0.026407</td>\n",
       "      <td>0.075065</td>\n",
       "      <td>0.213295</td>\n",
       "      <td>0.062244</td>\n",
       "      <td>1.858257</td>\n",
       "      <td>1.055305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.787979</td>\n",
       "      <td>0.043414</td>\n",
       "      <td>5.216515</td>\n",
       "      <td>8.933030</td>\n",
       "      <td>2.555305</td>\n",
       "      <td>3.610609</td>\n",
       "      <td>0.565009</td>\n",
       "      <td>0.214320</td>\n",
       "      <td>0.130311</td>\n",
       "      <td>0.020876</td>\n",
       "      <td>78.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 350 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  X0 X1  X2  ... cos_encode_2 cos_encode_3 cos_encode_4       y\n",
       "0   0   k  v  at  ...     0.396161     0.050612     0.268648  130.81\n",
       "1   6   k  t  av  ...     0.460063     0.157992     0.381311   88.53\n",
       "2   7  az  w   n  ...     0.205873     0.185820     0.013910   76.26\n",
       "3   9  az  t   n  ...     0.118635     0.130835     0.075874   80.62\n",
       "4  13  az  v   n  ...     0.214320     0.130311     0.020876   78.02\n",
       "\n",
       "[5 rows x 350 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the train and test csv files \n",
    "\n",
    "train = pd.read_csv(r'/content/drive/MyDrive/top_feature_train.csv')\n",
    "test = pd.read_csv(r'/content/drive/MyDrive/top_feature_test.csv')\n",
    "\n",
    "train = train.drop(['Unnamed: 0'], axis = 1)\n",
    "test = test.drop(['Unnamed: 0'], axis = 1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73nI09jvDlu2",
    "outputId": "42a45a48-792b-4ca1-e02c-f9931e1aa17d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape -  (4209, 350)\n",
      "test data shape  -  (4209, 349)\n"
     ]
    }
   ],
   "source": [
    "#Check the Shape of the test and train data\n",
    "print('train data shape - ', train.shape)\n",
    "print('test data shape  - ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7bkEh__MDlu3"
   },
   "outputs": [],
   "source": [
    "train.loc[train['y'] > 150] = 150\n",
    "\n",
    "y2 = train.y\n",
    "move = [ \t'ID' ,\t'X0' ,\t'X1' ,\t'X2' \t,'X3' ,'X5' ,\t'X6' ,\t'X8', 'y']\n",
    "x2 = train.drop(move, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNxqBfU4Dlu4",
    "outputId": "bb91d80a-816c-4a4a-ac80-ea7d8ab12b75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2820, 341) (2820,)\n",
      "(1389, 341) (1389,)\n"
     ]
    }
   ],
   "source": [
    "# Split train data into train-set and test-set\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2,y2, test_size = 0.33,random_state= 42)\n",
    "\n",
    "print(x_train2.shape, y_train2.shape)\n",
    "print(x_test2.shape, y_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElLnCUakDlu5"
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SquzTJKmDlu6",
    "outputId": "f4c8bb2c-f90c-4d4e-a294-132b8f45c9a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 466 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done 717 out of 720 | elapsed:  1.3min remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Estimator : DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=3,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=20, splitter='best')\n",
      "\n",
      "\n",
      "R2 metric : \n",
      "0 r2 score of the train data 0.5727993448261308 and test data 0.5517333068615851\n",
      "1 r2 score of the train data 0.5653722857340067 and test data 0.6649931070125705\n",
      "2 r2 score of the train data 0.5734600812347554 and test data 0.6037041847200402\n",
      "3 r2 score of the train data 0.6079480564620057 and test data 0.295841387440966\n",
      "4 r2 score of the train data 0.5780829128488911 and test data 0.5094437738972812\n",
      "5 r2 score of the train data 0.5770455134950616 and test data 0.5546179692984541\n",
      "6 r2 score of the train data 0.5714621388760321 and test data 0.63931768707822\n",
      "7 r2 score of the train data 0.5679556024559522 and test data 0.7047013902313545\n",
      "8 r2 score of the train data 0.58480623748573 and test data 0.4574489093196963\n",
      "9 r2 score of the train data 0.57678165997314 and test data 0.5543289851177138\n",
      "10 r2 score of the train data 0.5838871469899598 and test data 0.40937726622385506\n",
      "11 r2 score of the train data 0.5742070049919803 and test data 0.5752652423899043\n",
      "12 r2 score of the train data 0.5703728938595942 and test data 0.6575806943704936\n",
      "13 r2 score of the train data 0.5716939319770864 and test data 0.598721533902179\n",
      "14 r2 score of the train data 0.5701840060357541 and test data 0.6472752206392525\n",
      "\n",
      "Avg r2_score of train 0.5764039211497387 and test 0.5616233772335711\n",
      "Time taken - 1.3359219153722128 min\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=3,\n",
    "                            max_features='auto', max_leaf_nodes=None,\n",
    "                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                            min_samples_leaf=1, min_samples_split=2,\n",
    "                            min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                            random_state=None, splitter='best')\n",
    "\n",
    "params = {'max_depth' : [2,3,4,8,10,15],\n",
    "          'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "          'random_state' : [5,10,20,30],\n",
    "          }\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, 10, kfold = 15, search= 'grid')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "akgC4Z_40Xel",
    "outputId": "29edcde3-7236-4947-ef5b-2fe80d795b7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.5645815440213546 data\n"
     ]
    }
   ],
   "source": [
    "dt =  DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=3,\n",
    "                      max_features='auto', max_leaf_nodes=None,\n",
    "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                      min_samples_leaf=1, min_samples_split=2,\n",
    "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                      random_state=20, splitter='best')\n",
    "\n",
    "a = cross_val_score(dt, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qn7vSuQgDlu7"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jk5uaVF4Dlu7",
    "outputId": "26fab240-30d0-46cb-c24d-e8dd8b711955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 13.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Estimator : RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=3, max_features=0.95, max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=1e-05,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "R2 metric : \n",
      "0 r2 score of the train data 0.577087291813353 and test data 0.6132711188897396\n",
      "1 r2 score of the train data 0.5703996644280093 and test data 0.6609684185922715\n",
      "2 r2 score of the train data 0.578452544680822 and test data 0.6028701420087133\n",
      "3 r2 score of the train data 0.6125421985716001 and test data 0.30357217989243657\n",
      "4 r2 score of the train data 0.582456005055181 and test data 0.5311574076974697\n",
      "5 r2 score of the train data 0.581347147499635 and test data 0.558037383796935\n",
      "6 r2 score of the train data 0.5755225465600952 and test data 0.653998063252534\n",
      "7 r2 score of the train data 0.571482877918104 and test data 0.704416810834859\n",
      "8 r2 score of the train data 0.5880711478936098 and test data 0.4654762165866627\n",
      "9 r2 score of the train data 0.581164795256482 and test data 0.554894060385233\n",
      "10 r2 score of the train data 0.5867241938482605 and test data 0.46223717679878484\n",
      "11 r2 score of the train data 0.5771074180696558 and test data 0.5786484609591314\n",
      "12 r2 score of the train data 0.5749890540584395 and test data 0.6536878481220965\n",
      "13 r2 score of the train data 0.5753089240842089 and test data 0.6261519508819551\n",
      "14 r2 score of the train data 0.5744542619612625 and test data 0.645344399612696\n",
      "\n",
      "Avg r2_score of train 0.5804740047799146 and test 0.5743154425541012\n",
      "Time taken - 15.681973775227865 min\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor()\n",
    "\n",
    "params = {'n_estimators':[40,50,60,70,100],\n",
    "             'max_depth':[3,5,6,7,8],\n",
    "             'min_samples_split':[2,3,4,5,6,7,8,9,10],\n",
    "             'max_features': [0.80,.95, 1.0],\n",
    "             'min_samples_leaf': [1, 2,3,4,5,6,7,8,9],\n",
    "             'min_impurity_decrease':[1e-5,1e-4,1e-3,1e-2,1e-1,0,1,10]}\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, fold = 10, kfold=15, search= 'random') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6nXJyc90gV_",
    "outputId": "1907492f-7d0c-4710-8539-3b1f17a6fafb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.5722703062634319 data\n"
     ]
    }
   ],
   "source": [
    "rf =  RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=3, max_features=0.95, max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=1e-05,\n",
    "                      min_impurity_split=None, min_samples_leaf=1,\n",
    "                      min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
    "                      random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "a = cross_val_score(rf, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRvkTFNsDlu-"
   },
   "source": [
    "### XGBoost-Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZuogsycDlu_",
    "outputId": "e627c977-7ef4-46e0-bd3f-c57ea450e915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Estimator : XGBRFRegressor(base_score=0.5, colsample_bylevel=1, colsample_bynode=0.8,\n",
      "               colsample_bytree=1, gamma=0, learning_rate=1, max_delta_step=0,\n",
      "               max_depth=7, max_features=0.8, min_child_weight=1,\n",
      "               min_impurity_decrease=0.001, min_samples_leaf=4,\n",
      "               min_samples_split=2, missing=None, n_estimators=40, n_jobs=1,\n",
      "               nthread=None, objective='reg:linear', random_state=0,\n",
      "               reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "               silent=True, subsample=0.8, verbosity=1)\n",
      "\n",
      "\n",
      "R2 metric : \n",
      "0 r2 score of the train data 0.5607519129595249 and test data 0.612350904071567\n",
      "1 r2 score of the train data 0.5577277386771264 and test data 0.6554340512207613\n",
      "2 r2 score of the train data 0.5617422277259452 and test data 0.6032007707051259\n",
      "3 r2 score of the train data 0.5954512272952628 and test data 0.306385454262185\n",
      "4 r2 score of the train data 0.567338555840642 and test data 0.5264216134296651\n",
      "5 r2 score of the train data 0.5652550760126759 and test data 0.554397766212482\n",
      "6 r2 score of the train data 0.5588987037502464 and test data 0.6583819998690197\n",
      "7 r2 score of the train data 0.556428402163345 and test data 0.703099768991829\n",
      "8 r2 score of the train data 0.5716366105241955 and test data 0.47008749323113264\n",
      "9 r2 score of the train data 0.5650894144901676 and test data 0.5520598424562043\n",
      "10 r2 score of the train data 0.5698685506395984 and test data 0.486998617080977\n",
      "11 r2 score of the train data 0.5633495452041231 and test data 0.5760128251942953\n",
      "12 r2 score of the train data 0.558672400266895 and test data 0.6593011513004952\n",
      "13 r2 score of the train data 0.5600793827235035 and test data 0.63677973271229\n",
      "14 r2 score of the train data 0.5586598565803855 and test data 0.6518594742101987\n",
      "\n",
      "Avg r2_score of train 0.5647299736569091 and test 0.5768514309965485\n",
      "Time taken - 3.8507372379302978 min\n"
     ]
    }
   ],
   "source": [
    "clf = XGBRFRegressor(silent=True)\n",
    "\n",
    "xparams = {'learning_rate':[0.1,0.5,0.8,1],\n",
    "             'n_estimators':[70,80,100],\n",
    "             'max_depth':[2,3,4],\n",
    "             'colsample_bytree':[0.1,0.5,0.7,0.9,1],\n",
    "             'subsample':[0.2,0.3,0.5,1],\n",
    "             'gamma':[0.0001,0.001,0,0.1,0.01,0.5,1],\n",
    "             'reg_alpha':[0.00001,0.0001,0.001,0.01,0.1]}\n",
    "\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, fold = 10, kfold=15, search= 'random') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S4HvsGUa0qzP",
    "outputId": "f3226b5d-0387-4f50-ad00-6d204f9926bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.5730571735111031 data\n"
     ]
    }
   ],
   "source": [
    "xg =  XGBRFRegressor(base_score=0.5, colsample_bylevel=1, colsample_bynode=0.8,\n",
    "               colsample_bytree=1, gamma=0, learning_rate=1, max_delta_step=0,\n",
    "               max_depth=7, max_features=0.8, min_child_weight=1,\n",
    "               min_impurity_decrease=0.001, min_samples_leaf=4,\n",
    "               min_samples_split=2, missing=None, n_estimators=40, n_jobs=1,\n",
    "               nthread=None, objective='reg:linear', random_state=0,\n",
    "               reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "               silent=True, subsample=0.8, verbosity=1)\n",
    "\n",
    "a = cross_val_score(xg, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "On7n6eEcDlvB"
   },
   "source": [
    "## AdaBoost-Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RCqd5FZrDlvC",
    "outputId": "6c852288-b478-437a-d448-46880793aa5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 32.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Estimator : AdaBoostRegressor(base_estimator=None, learning_rate=0.0001, loss='square',\n",
      "                  n_estimators=150, random_state=30)\n",
      "\n",
      "\n",
      "R2 metric : \n",
      "0 r2 score of the train data 0.5646822713230479 and test data 0.6066783130115726\n",
      "1 r2 score of the train data 0.5577141547036 and test data 0.6649903462149656\n",
      "2 r2 score of the train data 0.5651393370662766 and test data 0.6033862254239895\n",
      "3 r2 score of the train data 0.5989253378984944 and test data 0.3064867419902134\n",
      "4 r2 score of the train data 0.5703661713907457 and test data 0.532300026745163\n",
      "5 r2 score of the train data 0.5687084265678528 and test data 0.5544782697611486\n",
      "6 r2 score of the train data 0.5626966400650278 and test data 0.6543380452537592\n",
      "7 r2 score of the train data 0.5566910900648376 and test data 0.7050220948487183\n",
      "8 r2 score of the train data 0.5756621801071371 and test data 0.46433697036193844\n",
      "9 r2 score of the train data 0.5682103360047548 and test data 0.5530743664423573\n",
      "10 r2 score of the train data 0.5787962790410337 and test data 0.40115919393392063\n",
      "11 r2 score of the train data 0.5669787210234464 and test data 0.5789391829398253\n",
      "12 r2 score of the train data 0.5617779914575695 and test data 0.6614607088330683\n",
      "13 r2 score of the train data 0.5632549126709887 and test data 0.6362939377829919\n",
      "14 r2 score of the train data 0.563774845950836 and test data 0.6504187322795321\n",
      "\n",
      "Avg r2_score of train 0.5682252463557101 and test 0.5715575437215442\n",
      "Time taken - 39.760059813658394 min\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostRegressor(base_estimator=None, learning_rate=0.0001,\n",
    "                        n_estimators=300, random_state=None, loss= 'linear')\n",
    "\n",
    "params = {'n_estimators'  : [100, 150, 200, ],\n",
    "          'learning_rate' :[0.0001,0.001,0.01, 0.1],\n",
    "          'loss' : [ 'linear', 'square', 'exponential'],\n",
    "          'random_state' : [10,20,30]\n",
    "          }\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, fold = 10, kfold = 15, search = 'random') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DfuxlU5N0yVz",
    "outputId": "60bcb2fc-52bf-4944-d584-30faab6928e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.5743669401083786 data\n"
     ]
    }
   ],
   "source": [
    "ab =   AdaBoostRegressor(base_estimator=None, learning_rate=0.0001, loss='square',\n",
    "                  n_estimators=150, random_state=30)\n",
    "\n",
    "a = cross_val_score(ab, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mGd1hZyDlvD"
   },
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbIufTtLDlvD",
    "outputId": "932264bc-72b3-4043-ab23-6115910f9719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed: 26.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 48.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Estimator : GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.01, loss='huber',\n",
      "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=1500,\n",
      "                          n_iter_no_change=11, presort='deprecated',\n",
      "                          random_state=10, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "R2 metric : \n",
      "0 r2 score of the train data 0.572231628764966 and test data 0.6037034985933161\n",
      "1 r2 score of the train data 0.5621641874751212 and test data 0.6414798160235033\n",
      "2 r2 score of the train data 0.5867592358384793 and test data 0.5801527896688994\n",
      "3 r2 score of the train data 0.6211634297112336 and test data 0.2921090496165797\n",
      "4 r2 score of the train data 0.5748619162004004 and test data 0.5269244313269791\n",
      "5 r2 score of the train data 0.5872705137166562 and test data 0.549299214543042\n",
      "6 r2 score of the train data 0.5855561004342713 and test data 0.6578667585099021\n",
      "7 r2 score of the train data 0.570752093827166 and test data 0.702863121942162\n",
      "8 r2 score of the train data 0.5842016164058297 and test data 0.4572405045212359\n",
      "9 r2 score of the train data 0.5798527918648275 and test data 0.5332054489958042\n",
      "10 r2 score of the train data 0.5820903105918269 and test data 0.4970823405618191\n",
      "11 r2 score of the train data 0.5844905309440279 and test data 0.5477665372635308\n",
      "12 r2 score of the train data 0.5732064802854702 and test data 0.6722729775204286\n",
      "13 r2 score of the train data 0.5794606697712166 and test data 0.6724396565967647\n",
      "14 r2 score of the train data 0.5778799612181722 and test data 0.6866115001225563\n",
      "\n",
      "Avg r2_score of train 0.5814627644699777 and test 0.5747345097204349\n",
      "Time taken - 64.8858946720759 min\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingRegressor(max_depth= 2, learning_rate= 0.1, random_state= 10,n_estimators=5000, \n",
    "                                n_iter_no_change = 11)\n",
    "\n",
    "params = {'n_estimators' : [500,800,1000, 1500, 2000],\n",
    "          'loss' : [ 'huber', 'exponential'],\n",
    "          'learning_rate' : [0.01, 0.01, 0.1],\n",
    "          'max_depth' : [3,4,5,7]\n",
    "          }\n",
    "\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, fold = 10, kfold = 15, search = 'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l22laB1sD7Cs",
    "outputId": "5a0d8880-5571-4532-91cc-771d97312f70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.5731033817060677 data\n"
     ]
    }
   ],
   "source": [
    " gb = GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
    "                          init=None, learning_rate=0.01, loss='huber',\n",
    "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
    "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                          min_samples_leaf=1, min_samples_split=2,\n",
    "                          min_weight_fraction_leaf=0.0, n_estimators=1500,\n",
    "                          n_iter_no_change=11, presort='deprecated',\n",
    "                          random_state=10, subsample=1.0, tol=0.0001,\n",
    "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
    " \n",
    " a = cross_val_score(gb, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M76pOiImDlvE"
   },
   "source": [
    "## LGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUmfMalBDlvE",
    "outputId": "6afeff95-04c3-46ef-821f-eba4745582be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 metric : \n",
      "0 r2 score of the train data 0.5997441404083625 and test data 0.6096233813618482\n",
      "1 r2 score of the train data 0.5958881929472761 and test data 0.6445588724260033\n",
      "2 r2 score of the train data 0.602526807697845 and test data 0.6007657087156126\n",
      "3 r2 score of the train data 0.6327607569536936 and test data 0.3070436943331817\n",
      "4 r2 score of the train data 0.6063989312693985 and test data 0.5403439972577462\n",
      "5 r2 score of the train data 0.6060046445533136 and test data 0.5558067093017696\n",
      "6 r2 score of the train data 0.5993389114393196 and test data 0.6537402142783227\n",
      "7 r2 score of the train data 0.5958897819905952 and test data 0.6964613240982211\n",
      "8 r2 score of the train data 0.6112823739876911 and test data 0.48196247922911584\n",
      "9 r2 score of the train data 0.6066215294634596 and test data 0.5536277630993041\n",
      "10 r2 score of the train data 0.607835933029663 and test data 0.5027366167589261\n",
      "11 r2 score of the train data 0.6068813272907176 and test data 0.5586564302402194\n",
      "12 r2 score of the train data 0.5974123440555079 and test data 0.6520383073567042\n",
      "13 r2 score of the train data 0.5979811420951997 and test data 0.6558092545600763\n",
      "14 r2 score of the train data 0.5989684485447244 and test data 0.6523321985442174\n",
      "\n",
      "Avg r2_score of train 0.6043690177151179 and test 0.577700463437418\n",
      "Time taken - 9.296628991762796 min\n"
     ]
    }
   ],
   "source": [
    "clf =   LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "              importance_type='split', learning_rate=0.001, max_depth=3,\n",
    "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
    "              n_estimators=5000, n_jobs=-1, num_leaves=6, objective=None,\n",
    "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
    "\n",
    "params = {'min_child_samples' : [10, 20,50],\n",
    "          'num_leaves' : [5,6],\n",
    "          'max_depth' : [2, 3, 5],\n",
    "          'n_estimators' : [1000,2000,4000,5000],\n",
    "          'learning_rate' : [0.0001,0.001,0.01,0.1]\n",
    "          }\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2.ravel(), fold = 10, kfold = 15, search = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O0CbuOYSECB9",
    "outputId": "3eeecf35-4506-490b-9785-c3970ba6c005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.5736623038048128 data\n"
     ]
    }
   ],
   "source": [
    "lg = LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "              importance_type='split', learning_rate=0.001, max_depth=3,\n",
    "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
    "              n_estimators=5000, n_jobs=-1, num_leaves=6, objective=None,\n",
    "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
    "\n",
    "\n",
    "a = cross_val_score(lg, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "UCppDfB5DlvF"
   },
   "outputs": [],
   "source": [
    "estimators = [ ('rf', RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=6, max_features=1.0, max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=0.0001,\n",
    "                      min_impurity_split=None, min_samples_leaf=4,\n",
    "                      min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
    "                      random_state=None, verbose=0, warm_start=False)),\n",
    "              \n",
    "              ('xgb', XGBRFRegressor(base_score=0.5, colsample_bylevel=1, colsample_bynode=0.8,\n",
    "               colsample_bytree=1, gamma=0, learning_rate=1, max_delta_step=0,\n",
    "               max_depth=5, max_features=0.95, min_child_weight=1,\n",
    "               min_impurity_decrease=0.0001, min_samples_leaf=2,\n",
    "               min_samples_split=4, missing=None, n_estimators=50, n_jobs=1,\n",
    "               nthread=None, objective='reg:linear', random_state=0,\n",
    "               reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "               silent=True, subsample=0.8, verbosity=1)),\n",
    "              \n",
    "              ('lb', LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "              importance_type='split', learning_rate=0.001, max_depth=3,\n",
    "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
    "              n_estimators=5000, n_jobs=-1, num_leaves=6, objective=None,\n",
    "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0))\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mWErYGg1BqMr",
    "outputId": "0b1c390c-c76c-4ba7-8927-07c2dda52a2c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Score: 0.575714581019241\n",
      "Standard Deviation: 0.08823219159340108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 39.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 39.0min finished\n"
     ]
    }
   ],
   "source": [
    "stack = StackingRegressor(estimators= estimators,\n",
    "                          final_estimator= Ridge(), \n",
    "                          )\n",
    "\n",
    "\n",
    "cv_score = cross_val_score(stack, x2, y2.ravel(), scoring='r2', cv= 10, verbose=5, n_jobs=-1)\n",
    "print('Mean Score:',cv_score.mean())\n",
    "print('Standard Deviation:',cv_score.std())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZdSaIgXPEaEF",
    "outputId": "c73e6bae-0754-4441-b7cd-9aa6db07f7f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------------------------------------------------+------------------+--------------+---------------+\n",
      "|       MODELS      |                          FEATURES                          | CROSS-VALIDATION | PUBLIC SCORE | PRIVATE SCORE |\n",
      "+-------------------+------------------------------------------------------------+------------------+--------------+---------------+\n",
      "|   DECISION TREE   | PCA(100) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES |      0.5616      |   0.54541    |    0.52796    |\n",
      "|   RANDOM FOREST   | PCA(100) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES |      0.5743      |   0.54556    |    0.53966    |\n",
      "|      XGBOOST      | PCA(100) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES |      0.5768      |   0.54345    |    0.53673    |\n",
      "|     ADA-BOOST     | PCA(100) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES |      0.5715      |   0.54539    |    0.53996    |\n",
      "| GRADIENT BOOSTING | PCA(100) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES |      0.5847      |   0.54321    |    0.53868    |\n",
      "|     LIGHT GBM     | PCA(100) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES |      0.5775      |   0.55793    |    0.54630    |\n",
      "|  STCKED-ENSEMBLE  | PCA(100) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES |      0.5757      |   0.55442    |    0.54515    |\n",
      "+-------------------+------------------------------------------------------------+------------------+--------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "col = ['MODELS', 'FEATURES', 'CROSS-VALIDATION' , 'PUBLIC SCORE', 'PRIVATE SCORE']\n",
    "\n",
    "tb = PrettyTable() \n",
    "\n",
    "tb.add_column(col[0], ['DECISION TREE', 'RANDOM FOREST', 'XGBOOST', 'ADA-BOOST', 'GRADIENT BOOSTING', 'LIGHT GBM', 'STCKED-ENSEMBLE'])\n",
    "\n",
    "tb.add_column(col[1], ['PCA(100) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES','PCA(100) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES',\n",
    "                       'PCA(100) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES','PCA(100) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES',\n",
    "                       'PCA(100) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES','PCA(100) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES',\n",
    "                       'PCA(100) + BINARY + LABEL + Y 150 CLIP +SYNTHETIC FEATURES',])\n",
    "\n",
    "tb.add_column(col[2], ['0.5616', '0.5743', '0.5768', '0.5715', '0.5847', '0.5775', '0.5757'])\n",
    "\n",
    "tb.add_column(col[3], ['0.54541', '0.54556', '0.54345', '0.54539', '0.54321', '0.55793', '0.55442'])\n",
    "\n",
    "tb.add_column(col[4], ['0.52796', '0.53966', '0.53673', '0.53996', '0.53868', '0.54630', '0.54515'])\n",
    "\n",
    "print(tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vNzFl1gpEhC"
   },
   "source": [
    "## OBSERVATION\n",
    "\n",
    "\n",
    "*   This dataset contain 100 PCA features from binary and label encode features. With target y clip at 150secs\n",
    "\n",
    "*   In this dataset light gradient boosting perform well than other. LGB got 0.55793 in public and 0.54630 private score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_IT55YQb2QU"
   },
   "source": [
    "# Models with selected top features using selectkbest method\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "qwtr8Jx1b2QX",
    "outputId": "40103f30-bce6-4c51-f0cd-b9514287602e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X10</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>X27</th>\n",
       "      <th>X28</th>\n",
       "      <th>X29</th>\n",
       "      <th>X31</th>\n",
       "      <th>X35</th>\n",
       "      <th>X37</th>\n",
       "      <th>X43</th>\n",
       "      <th>X44</th>\n",
       "      <th>X45</th>\n",
       "      <th>X46</th>\n",
       "      <th>X47</th>\n",
       "      <th>X48</th>\n",
       "      <th>X50</th>\n",
       "      <th>X51</th>\n",
       "      <th>X52</th>\n",
       "      <th>X54</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X61</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>X66</th>\n",
       "      <th>X68</th>\n",
       "      <th>X69</th>\n",
       "      <th>X71</th>\n",
       "      <th>X73</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X79</th>\n",
       "      <th>X80</th>\n",
       "      <th>X81</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_feature21</th>\n",
       "      <th>pca_feature22</th>\n",
       "      <th>pca_feature24</th>\n",
       "      <th>pca_feature25</th>\n",
       "      <th>pca_feature28</th>\n",
       "      <th>pca_feature30</th>\n",
       "      <th>pca_feature32</th>\n",
       "      <th>pca_feature39</th>\n",
       "      <th>pca_feature43</th>\n",
       "      <th>pca_feature44</th>\n",
       "      <th>pca_feature50</th>\n",
       "      <th>pca_feature52</th>\n",
       "      <th>pca_feature53</th>\n",
       "      <th>pca_feature59</th>\n",
       "      <th>pca_feature60</th>\n",
       "      <th>pca_feature63</th>\n",
       "      <th>pca_feature66</th>\n",
       "      <th>pca_feature70</th>\n",
       "      <th>pca_feature73</th>\n",
       "      <th>pca_feature74</th>\n",
       "      <th>pca_feature77</th>\n",
       "      <th>pca_feature78</th>\n",
       "      <th>pca_feature81</th>\n",
       "      <th>pca_feature83</th>\n",
       "      <th>pca_feature86</th>\n",
       "      <th>pca_feature93</th>\n",
       "      <th>pca_feature95</th>\n",
       "      <th>pca_feature97</th>\n",
       "      <th>pca_feature98</th>\n",
       "      <th>X315_314_51_340</th>\n",
       "      <th>X299_300_301_328</th>\n",
       "      <th>X46_263_119_261</th>\n",
       "      <th>X136_118_136_355</th>\n",
       "      <th>qua_encode_2</th>\n",
       "      <th>qua_encode_3</th>\n",
       "      <th>cos_encode_1</th>\n",
       "      <th>cos_encode_3</th>\n",
       "      <th>cos_encode_4</th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.182578</td>\n",
       "      <td>-0.128126</td>\n",
       "      <td>0.178685</td>\n",
       "      <td>-0.104251</td>\n",
       "      <td>-0.528341</td>\n",
       "      <td>-0.116039</td>\n",
       "      <td>0.209134</td>\n",
       "      <td>-0.354578</td>\n",
       "      <td>0.946379</td>\n",
       "      <td>0.641226</td>\n",
       "      <td>0.246514</td>\n",
       "      <td>-0.161980</td>\n",
       "      <td>0.548344</td>\n",
       "      <td>0.760651</td>\n",
       "      <td>-0.152505</td>\n",
       "      <td>0.962756</td>\n",
       "      <td>-0.365927</td>\n",
       "      <td>0.270162</td>\n",
       "      <td>0.173254</td>\n",
       "      <td>-0.457502</td>\n",
       "      <td>0.013302</td>\n",
       "      <td>-0.052985</td>\n",
       "      <td>0.247189</td>\n",
       "      <td>0.623784</td>\n",
       "      <td>0.438775</td>\n",
       "      <td>-0.233706</td>\n",
       "      <td>-0.040995</td>\n",
       "      <td>-0.003752</td>\n",
       "      <td>-0.117690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.042486</td>\n",
       "      <td>11.450113</td>\n",
       "      <td>0.108660</td>\n",
       "      <td>0.108660</td>\n",
       "      <td>0.307240</td>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.991160</td>\n",
       "      <td>-0.545977</td>\n",
       "      <td>-0.276158</td>\n",
       "      <td>-0.656953</td>\n",
       "      <td>-0.734347</td>\n",
       "      <td>0.026911</td>\n",
       "      <td>0.658565</td>\n",
       "      <td>-0.255818</td>\n",
       "      <td>0.176963</td>\n",
       "      <td>0.152777</td>\n",
       "      <td>-0.171294</td>\n",
       "      <td>0.031739</td>\n",
       "      <td>-0.039456</td>\n",
       "      <td>0.214851</td>\n",
       "      <td>0.364820</td>\n",
       "      <td>-0.508838</td>\n",
       "      <td>-0.300376</td>\n",
       "      <td>0.015067</td>\n",
       "      <td>-0.104844</td>\n",
       "      <td>-0.064088</td>\n",
       "      <td>-0.061016</td>\n",
       "      <td>-0.220592</td>\n",
       "      <td>-0.045568</td>\n",
       "      <td>-0.006343</td>\n",
       "      <td>-0.320449</td>\n",
       "      <td>0.136784</td>\n",
       "      <td>-0.086269</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.012419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.555795</td>\n",
       "      <td>11.143521</td>\n",
       "      <td>0.094123</td>\n",
       "      <td>0.107239</td>\n",
       "      <td>0.386071</td>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690290</td>\n",
       "      <td>-0.187279</td>\n",
       "      <td>1.330146</td>\n",
       "      <td>0.390737</td>\n",
       "      <td>-0.217453</td>\n",
       "      <td>-0.563563</td>\n",
       "      <td>0.301389</td>\n",
       "      <td>0.231312</td>\n",
       "      <td>0.251452</td>\n",
       "      <td>0.245857</td>\n",
       "      <td>-0.170609</td>\n",
       "      <td>-0.645932</td>\n",
       "      <td>0.023164</td>\n",
       "      <td>0.127338</td>\n",
       "      <td>0.267930</td>\n",
       "      <td>-0.058629</td>\n",
       "      <td>-0.354888</td>\n",
       "      <td>0.025130</td>\n",
       "      <td>-0.434715</td>\n",
       "      <td>0.197347</td>\n",
       "      <td>0.157569</td>\n",
       "      <td>0.100554</td>\n",
       "      <td>-0.488942</td>\n",
       "      <td>0.372205</td>\n",
       "      <td>-0.384254</td>\n",
       "      <td>-0.176610</td>\n",
       "      <td>-0.056234</td>\n",
       "      <td>0.395914</td>\n",
       "      <td>1.056965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.964781</td>\n",
       "      <td>351.430285</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.376125</td>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282964</td>\n",
       "      <td>-0.034721</td>\n",
       "      <td>1.515710</td>\n",
       "      <td>-0.722524</td>\n",
       "      <td>0.072271</td>\n",
       "      <td>-0.293604</td>\n",
       "      <td>0.068063</td>\n",
       "      <td>-0.439959</td>\n",
       "      <td>0.314597</td>\n",
       "      <td>-0.010401</td>\n",
       "      <td>0.024335</td>\n",
       "      <td>0.258586</td>\n",
       "      <td>-0.064303</td>\n",
       "      <td>-0.167383</td>\n",
       "      <td>0.260068</td>\n",
       "      <td>-0.130885</td>\n",
       "      <td>-0.018400</td>\n",
       "      <td>0.026913</td>\n",
       "      <td>-0.054760</td>\n",
       "      <td>-0.043794</td>\n",
       "      <td>0.043378</td>\n",
       "      <td>-0.100348</td>\n",
       "      <td>-0.297885</td>\n",
       "      <td>0.150184</td>\n",
       "      <td>0.336399</td>\n",
       "      <td>-0.064002</td>\n",
       "      <td>0.114576</td>\n",
       "      <td>0.360489</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.157439</td>\n",
       "      <td>349.571432</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.376125</td>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022836</td>\n",
       "      <td>-0.041093</td>\n",
       "      <td>0.570398</td>\n",
       "      <td>-0.057357</td>\n",
       "      <td>0.012085</td>\n",
       "      <td>0.379070</td>\n",
       "      <td>-0.289574</td>\n",
       "      <td>-0.302103</td>\n",
       "      <td>-0.238878</td>\n",
       "      <td>0.122182</td>\n",
       "      <td>0.145761</td>\n",
       "      <td>0.102616</td>\n",
       "      <td>-0.039255</td>\n",
       "      <td>-0.088233</td>\n",
       "      <td>0.254461</td>\n",
       "      <td>0.207313</td>\n",
       "      <td>-0.278137</td>\n",
       "      <td>0.230387</td>\n",
       "      <td>-0.312594</td>\n",
       "      <td>0.083544</td>\n",
       "      <td>0.190114</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>-0.180643</td>\n",
       "      <td>0.136394</td>\n",
       "      <td>0.268128</td>\n",
       "      <td>-0.121553</td>\n",
       "      <td>-0.047947</td>\n",
       "      <td>0.041592</td>\n",
       "      <td>0.187224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.228690</td>\n",
       "      <td>361.198271</td>\n",
       "      <td>0.004612</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>0.376125</td>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X10  X12  X13  X14  ...  cos_encode_3  cos_encode_4  ID       y\n",
       "0    0    0    1    0  ...      0.108660      0.307240   0  130.81\n",
       "1    0    0    0    0  ...      0.107239      0.386071   6   88.53\n",
       "2    0    0    0    0  ...      0.003774      0.376125   7   76.26\n",
       "3    0    0    0    0  ...      0.003789      0.376125   9   80.62\n",
       "4    0    0    0    0  ...      0.003685      0.376125  13   78.02\n",
       "\n",
       "[5 rows x 252 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the train and test csv files \n",
    "\n",
    "train = pd.read_csv(r'/content/drive/MyDrive/Datasets/selectK_train_feature.csv')\n",
    "test = pd.read_csv(r'/content/drive/MyDrive/Datasets/selectK_test_feature.csv')\n",
    "\n",
    "train = train.drop(['Unnamed: 0'], axis = 1)\n",
    "test = test.drop(['Unnamed: 0'], axis = 1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2CNWSqcb2Qb",
    "outputId": "809ffcb6-2fdb-4697-ff7b-697138bf88cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape -  (4209, 252)\n",
      "test data shape  -  (4209, 251)\n"
     ]
    }
   ],
   "source": [
    "#Check the Shape of the test and train data\n",
    "print('train data shape - ', train.shape)\n",
    "print('test data shape  - ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "rzVywQ6ab2Qc"
   },
   "outputs": [],
   "source": [
    "# declare the train set and label\n",
    "train.loc[train['y'] > 150] = 150\n",
    "y2 = train.y\n",
    "x2 = train.drop(['y', 'ID'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYwpS91jb2Qd",
    "outputId": "4d2cb68a-78c3-4bee-91bf-611ed7cab126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2820, 250) (2820,)\n",
      "(1389, 250) (1389,)\n"
     ]
    }
   ],
   "source": [
    "# Split train data into train-set and test-set\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2,y2, test_size = 0.33,random_state= 42)\n",
    "\n",
    "print(x_train2.shape, y_train2.shape)\n",
    "print(x_test2.shape, y_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdpE_TUwb2Qf"
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-RWrqZlNb2Qg",
    "outputId": "aab15fd8-6d68-4689-e13d-13b181f6e444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 metric : \n",
      "0 r2 score of the train data 0.7003943217596944 and test data 0.5912088567314289\n",
      "1 r2 score of the train data 0.684772877128098 and test data 0.7461049970562634\n",
      "2 r2 score of the train data 0.7024668433891952 and test data 0.5695775837295918\n",
      "3 r2 score of the train data 0.6955558898354829 and test data 0.6247256843562159\n",
      "4 r2 score of the train data 0.6943306686873321 and test data 0.6938806609949865\n",
      "5 r2 score of the train data 0.6917795390935819 and test data 0.5715765496011846\n",
      "6 r2 score of the train data 0.6950587650032459 and test data 0.6254903902405267\n",
      "7 r2 score of the train data 0.6899252956182615 and test data 0.7482496095026618\n",
      "8 r2 score of the train data 0.7066464250517441 and test data 0.4451958898852242\n",
      "9 r2 score of the train data 0.699592124849862 and test data 0.5409245741315845\n",
      "10 r2 score of the train data 0.7090500610772879 and test data 0.3688190526192887\n",
      "11 r2 score of the train data 0.6980781796780453 and test data 0.632043078306469\n",
      "12 r2 score of the train data 0.6959999890239887 and test data 0.6536206550723016\n",
      "13 r2 score of the train data 0.6938200362681952 and test data 0.6973450444266769\n",
      "14 r2 score of the train data 0.6936533776743699 and test data 0.5191145080931587\n",
      "\n",
      "Avg r2_score of train 0.6967416262758924 and test 0.6018584756498376\n",
      "Time taken - 0.0696996808052063 min\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=8,\n",
    "                      max_features='auto', max_leaf_nodes=None,\n",
    "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                      min_samples_leaf=1, min_samples_split=2,\n",
    "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                      random_state=10, splitter='best')\n",
    "\n",
    "params = {'max_depth' : [2,3,4,8,10,15],\n",
    "          'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "          'random_state' : [5,10,20,30],\n",
    "          }\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, 10, kfold = 15, search= False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7M-HN1Etb2Qi",
    "outputId": "0785c045-8135-493e-e43e-bff3f3b2bf83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.6350922926910991 data\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=3,\n",
    "                            max_features='auto',\n",
    "                            min_impurity_decrease=0.0,\n",
    "                            min_samples_leaf=1, min_samples_split=2,\n",
    "                            min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                            splitter='best')\n",
    "\n",
    "\n",
    "a = cross_val_score(dt, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFX7nX9ub2Qk"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NjdArcr2b2Ql",
    "outputId": "791fabbc-2f6c-40b4-9bd7-43b8767ffc9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 metric : \n",
      "0 r2 score of the train data 0.6491851497180579 and test data 0.6722657818421716\n",
      "1 r2 score of the train data 0.6428875293997556 and test data 0.7650168179513238\n",
      "2 r2 score of the train data 0.6543022991441494 and test data 0.6009548522547989\n",
      "3 r2 score of the train data 0.651093238820595 and test data 0.6413429640388058\n",
      "4 r2 score of the train data 0.6486153400378359 and test data 0.6732278735764214\n",
      "5 r2 score of the train data 0.6500914264009571 and test data 0.6524032274886278\n",
      "6 r2 score of the train data 0.650940549896302 and test data 0.6542854706156918\n",
      "7 r2 score of the train data 0.6447753756785972 and test data 0.7542422390060914\n",
      "8 r2 score of the train data 0.6659204711262184 and test data 0.46907503683814333\n",
      "9 r2 score of the train data 0.6517637548732664 and test data 0.6296769532934854\n",
      "10 r2 score of the train data 0.6605605207274278 and test data 0.49104247104708254\n",
      "11 r2 score of the train data 0.6507621664241039 and test data 0.6474150149129719\n",
      "12 r2 score of the train data 0.6492585389063131 and test data 0.659040789441843\n",
      "13 r2 score of the train data 0.6478413435266211 and test data 0.6878571251898438\n",
      "14 r2 score of the train data 0.6498242678129074 and test data 0.6548025156628345\n",
      "\n",
      "Avg r2_score of train 0.6511881314995407 and test 0.6435099422106758\n",
      "Time taken - 0.5376898010571798 min\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=3, max_features=0.8, max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=1e-05,\n",
    "                      min_impurity_split=None, min_samples_leaf=5,\n",
    "                      min_samples_split=9, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=40, n_jobs=None, oob_score=False,\n",
    "                      random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "params = {'n_estimators':[40,50,60,70,100],\n",
    "             'max_depth':[3,5,6,7,8],\n",
    "             'min_samples_split':[2,3,4,5,6,7,8,9,10],\n",
    "             'max_features': [0.80,.95, 1.0],\n",
    "             'min_samples_leaf': [1, 2,3,4,5,6,7,8,9],\n",
    "             'min_impurity_decrease':[1e-5,1e-4,1e-3,1e-2,1e-1,0,1,10]}\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, fold = 10, kfold=15, search= False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hj3iLcEEb2Qm",
    "outputId": "4591b45a-73a9-4aeb-9522-a7ea51b40d0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.6411188337826735 data\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=3, max_features=0.8, max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=1e-05,\n",
    "                      min_impurity_split=None, min_samples_leaf=5,\n",
    "                      min_samples_split=9, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=40, n_jobs=None, oob_score=False,\n",
    "                      random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "a = cross_val_score(rf, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-VlnESxb2Qo"
   },
   "source": [
    "### XGBoost-Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KpZy2Fyxb2Qo",
    "outputId": "fbcbcec7-7daf-4abd-c3ba-d61a5d4852f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 metric : \n",
      "0 r2 score of the train data 0.6067502601868848 and test data 0.6374083132665591\n",
      "1 r2 score of the train data 0.6037579887656499 and test data 0.6953451163213371\n",
      "2 r2 score of the train data 0.6121444549439352 and test data 0.6011016381585581\n",
      "3 r2 score of the train data 0.6129187708599382 and test data 0.5565082186028582\n",
      "4 r2 score of the train data 0.6113841767426726 and test data 0.582448928624506\n",
      "5 r2 score of the train data 0.6078223907106232 and test data 0.6276658565426563\n",
      "6 r2 score of the train data 0.6084467931525492 and test data 0.6559734999802659\n",
      "7 r2 score of the train data 0.603205051745912 and test data 0.7092297719647569\n",
      "8 r2 score of the train data 0.6226020717930794 and test data 0.46860069407268745\n",
      "9 r2 score of the train data 0.6124662945950516 and test data 0.5626195379397068\n",
      "10 r2 score of the train data 0.6185700634680764 and test data 0.48692268287664975\n",
      "11 r2 score of the train data 0.608856439703718 and test data 0.6154646014250558\n",
      "12 r2 score of the train data 0.6061588075086194 and test data 0.6581597523169269\n",
      "13 r2 score of the train data 0.6072817595908033 and test data 0.6407171369439164\n",
      "14 r2 score of the train data 0.6060176585456536 and test data 0.6507545607215774\n",
      "\n",
      "Avg r2_score of train 0.6098921988208779 and test 0.6099280206505344\n",
      "Time taken - 0.6381794929504394 min\n"
     ]
    }
   ],
   "source": [
    "clf = XGBRFRegressor(base_score=0.5, colsample_bylevel=1, colsample_bynode=0.8,\n",
    "               colsample_bytree=1, gamma=0, learning_rate=1, max_delta_step=0,\n",
    "               max_depth=15, max_features='log2', min_child_weight=1,\n",
    "               missing=None, n_estimators=100, n_jobs=1, nthread=None,\n",
    "               objective='reg:linear', random_state=5, reg_alpha=0,\n",
    "               reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "               subsample=0.8, verbosity=1)\n",
    "\n",
    "xparams = {'learning_rate':[0.1,0.5,0.8,1],\n",
    "             'n_estimators':[70,80,100],\n",
    "             'max_depth':[2,3,4],\n",
    "             'colsample_bytree':[0.1,0.5,0.7,0.9,1],\n",
    "             'subsample':[0.2,0.3,0.5,1],\n",
    "             'gamma':[0.0001,0.001,0,0.1,0.01,0.5,1],\n",
    "             'reg_alpha':[0.00001,0.0001,0.001,0.01,0.1]}\n",
    "\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, fold = 10, kfold=15, search= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de2zPsEab2Qp",
    "outputId": "08619908-38d7-4cc1-8456-c9e32ea79c6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.6096710572369947 data\n"
     ]
    }
   ],
   "source": [
    " xg = XGBRFRegressor(colsample_bylevel=1,\n",
    "               colsample_bynode=0.8, colsample_bytree=1, gamma=0,\n",
    "               learning_rate=1, max_delta_step=0, max_depth=5,\n",
    "               max_features=0.95, min_child_weight=1, min_impurity_decrease=1,\n",
    "               min_samples_leaf=1, min_samples_split=5, missing=None,\n",
    "               n_estimators=100, n_jobs=1, nthread=None, objective='reg:linear',\n",
    "               random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "               seed=None, silent=True, subsample=0.8, verbosity=1)\n",
    "\n",
    "a = cross_val_score(xg, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kg14IRNMb2Qq"
   },
   "source": [
    "AdaBoost-Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HowvXdfGb2Qq",
    "outputId": "366576bf-b263-40ce-a5cb-4eed1ba88717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 metric : \n",
      "0 r2 score of the train data 0.6406019024644523 and test data 0.6641913063532133\n",
      "1 r2 score of the train data 0.6341117815098307 and test data 0.7675518739100321\n",
      "2 r2 score of the train data 0.6448193857404521 and test data 0.601364590744293\n",
      "3 r2 score of the train data 0.6420025644845055 and test data 0.6401058176407162\n",
      "4 r2 score of the train data 0.6426822251515699 and test data 0.6709984599032441\n",
      "5 r2 score of the train data 0.6412649710061986 and test data 0.6561873993797418\n",
      "6 r2 score of the train data 0.6414199311868302 and test data 0.6550053083325136\n",
      "7 r2 score of the train data 0.635692428613147 and test data 0.750110156147811\n",
      "8 r2 score of the train data 0.6566658201904927 and test data 0.4667308312720433\n",
      "9 r2 score of the train data 0.6433253839092598 and test data 0.6252818172649386\n",
      "10 r2 score of the train data 0.6530673875304205 and test data 0.4887717640412784\n",
      "11 r2 score of the train data 0.6424865119330938 and test data 0.6470462212100361\n",
      "12 r2 score of the train data 0.6408561893286236 and test data 0.6616694666615984\n",
      "13 r2 score of the train data 0.6397242178987328 and test data 0.6801148107924511\n",
      "14 r2 score of the train data 0.6405964615369728 and test data 0.6550850005146253\n",
      "\n",
      "Avg r2_score of train 0.6426211441656389 and test 0.6420143216112356\n",
      "Time taken - 2.685768520832062 min\n"
     ]
    }
   ],
   "source": [
    "clf =  AdaBoostRegressor(base_estimator=None, learning_rate=0.0001, loss='linear',\n",
    "                  n_estimators=100, random_state=10)\n",
    "\n",
    "\n",
    "params = {'n_estimators'  : [100, 150, 200, ],\n",
    "          'learning_rate' :[0.0001,0.001,0.01, 0.1],\n",
    "          'loss' : [ 'linear', 'square', 'exponential'],\n",
    "          'random_state' : [10,20,30]\n",
    "          }\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, fold = 10, kfold = 15, search = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t09GR8lyb2Qs",
    "outputId": "538962d8-069c-481c-ac74-034df7779821"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.6395565714731158 data\n"
     ]
    }
   ],
   "source": [
    " ab =   AdaBoostRegressor(base_estimator=None, learning_rate=0.0001, loss='linear',\n",
    "                  n_estimators=100, random_state=10)\n",
    "\n",
    "\n",
    "a = cross_val_score(ab, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsv61Kreb2Qt"
   },
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPw8c1pAb2Qt",
    "outputId": "d2ef950b-b1e9-4116-b66f-1f8ef939bff0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 metric : \n",
      "0 r2 score of the train data 0.646898352654415 and test data 0.6463232721630487\n",
      "1 r2 score of the train data 0.6445815700448241 and test data 0.7630028652459149\n",
      "2 r2 score of the train data 0.6638708224569014 and test data 0.5820050454376444\n",
      "3 r2 score of the train data 0.6643729193689359 and test data 0.6298306073660422\n",
      "4 r2 score of the train data 0.6452857437229575 and test data 0.6703858624196001\n",
      "5 r2 score of the train data 0.6467163192346321 and test data 0.6466422501820477\n",
      "6 r2 score of the train data 0.6520411010671734 and test data 0.6518687281616424\n",
      "7 r2 score of the train data 0.6511587363040845 and test data 0.7573584179324647\n",
      "8 r2 score of the train data 0.6688157545177016 and test data 0.453579856520536\n",
      "9 r2 score of the train data 0.6498989292469194 and test data 0.6088874846193633\n",
      "10 r2 score of the train data 0.6721223434084025 and test data 0.49579802946005624\n",
      "11 r2 score of the train data 0.6556792100878011 and test data 0.6329712960936003\n",
      "12 r2 score of the train data 0.6613676334095353 and test data 0.6671419303636512\n",
      "13 r2 score of the train data 0.6624697875464138 and test data 0.7195585718225759\n",
      "14 r2 score of the train data 0.6567325364921577 and test data 0.6894664334886403\n",
      "\n",
      "Avg r2_score of train 0.6561341173041902 and test 0.6409880434184552\n",
      "Time taken - 8.37012676000595 min\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
    "                          init=None, learning_rate=0.01, loss='huber',\n",
    "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
    "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                          min_samples_leaf=1, min_samples_split=2,\n",
    "                          min_weight_fraction_leaf=0.0, n_estimators=2000,\n",
    "                          n_iter_no_change=11, presort='deprecated',\n",
    "                          random_state=10, subsample=1.0, tol=0.0001,\n",
    "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "\n",
    "params = {'n_estimators' : [800,1000, 1500, 2000, 2500],\n",
    "          'loss' : [ 'huber', 'exponential'],\n",
    "          'learning_rate' : [0.01, 0.01, 0.1],\n",
    "          'max_depth' : [3,4,5,7]\n",
    "          }\n",
    "\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2, fold = 10, kfold = 15, search = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MnWI2S7ob2Qu",
    "outputId": "21aee98c-ef16-4175-b777-12452552d71d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.6401325221008258 data\n"
     ]
    }
   ],
   "source": [
    "gb =  GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
    "                          init=None, learning_rate=0.01, loss='huber',\n",
    "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
    "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                          min_samples_leaf=1, min_samples_split=2,\n",
    "                          min_weight_fraction_leaf=0.0, n_estimators=2000,\n",
    "                          n_iter_no_change=11, presort='deprecated',\n",
    "                          random_state=10, subsample=1.0, tol=0.0001,\n",
    "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "\n",
    "a = cross_val_score(gb, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2M4lB6s0b2Qu"
   },
   "source": [
    "## LGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iu7OkPrab2Qv",
    "outputId": "f5b0a970-c523-4d9c-9d65-e8c7867c0286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 metric : \n",
      "0 r2 score of the train data 0.7572398922837325 and test data 0.648629927585285\n",
      "1 r2 score of the train data 0.7559447382612352 and test data 0.7524994967038349\n",
      "2 r2 score of the train data 0.7635946493631556 and test data 0.5796051680603062\n",
      "3 r2 score of the train data 0.7616028837108777 and test data 0.6283320314911397\n",
      "4 r2 score of the train data 0.756111951588603 and test data 0.6669960134479473\n",
      "5 r2 score of the train data 0.7592501493147876 and test data 0.6344725589160572\n",
      "6 r2 score of the train data 0.757831426306504 and test data 0.6637281324013\n",
      "7 r2 score of the train data 0.7549205437978412 and test data 0.7264772198521539\n",
      "8 r2 score of the train data 0.7704056362229155 and test data 0.47265909739244094\n",
      "9 r2 score of the train data 0.7606748853035004 and test data 0.629765276411993\n",
      "10 r2 score of the train data 0.7635879477252655 and test data 0.49182201718973395\n",
      "11 r2 score of the train data 0.7608877785525503 and test data 0.6206099747367849\n",
      "12 r2 score of the train data 0.7592847885219717 and test data 0.6312332206937824\n",
      "13 r2 score of the train data 0.7559390326059556 and test data 0.7038297346424771\n",
      "14 r2 score of the train data 0.755889171858096 and test data 0.6467577178304664\n",
      "\n",
      "Avg r2_score of train 0.7595443650277994 and test 0.6331611724903802\n",
      "Time taken - 4.181476438045502 min\n"
     ]
    }
   ],
   "source": [
    "clf = LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "              importance_type='split', learning_rate=0.01, max_depth=3,\n",
    "              min_child_samples=50, min_child_weight=0.001, min_split_gain=0.0,\n",
    "              n_estimators=4000, n_jobs=-1, num_leaves=5, objective=None,\n",
    "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
    "\n",
    "\n",
    "params = {'min_child_samples' : [10, 20,50],\n",
    "          'num_leaves' : [5,6],\n",
    "          'max_depth' : [2, 3, 5],\n",
    "          'n_estimators' : [1000,2000,4000,5000],\n",
    "          'learning_rate' : [0.0001,0.001,0.01,0.1]\n",
    "          }\n",
    "\n",
    "kfold_grid_search(clf, params, x2, y2.ravel(), fold = 10, kfold = 15, search = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9gP-dxzb2Qv",
    "outputId": "15b9c8a2-ac41-49c2-f463-e5cdcd7c28dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score 0.6280864312506385 data\n"
     ]
    }
   ],
   "source": [
    "lb =  LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "              importance_type='split', learning_rate=0.01, max_depth=3,\n",
    "              min_child_samples=50, min_child_weight=0.001, min_split_gain=0.0,\n",
    "              n_estimators=4000, n_jobs=-1, num_leaves=5, objective=None,\n",
    "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
    "\n",
    "\n",
    "a = cross_val_score(lb, x2, y2, scoring= 'r2', cv= 10)\n",
    "print(f'R^2 Score {np.mean(a)} data' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uaIpk6wTcOCU"
   },
   "outputs": [],
   "source": [
    "estimators = [ ('rf', RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=5, max_features=0.95, max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=0.001,\n",
    "                      min_impurity_split=None, min_samples_leaf=2,\n",
    "                      min_samples_split=8, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=70, n_jobs=None, oob_score=False,\n",
    "                      random_state=None, verbose=0, warm_start=False)),\n",
    "              \n",
    "                ('xg', XGBRFRegressor(colsample_bylevel=1,\n",
    "               colsample_bynode=0.8, colsample_bytree=1, gamma=0,\n",
    "               learning_rate=1, max_delta_step=0, max_depth=5,\n",
    "               max_features=0.95, min_child_weight=1, min_impurity_decrease=1,\n",
    "               min_samples_leaf=1, min_samples_split=5, missing=None,\n",
    "               n_estimators=100, n_jobs=1, nthread=None, objective='reg:linear',\n",
    "               random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "               seed=None, silent=True, subsample=0.8, verbosity=1)),\n",
    "              \n",
    "\n",
    "              ('gb', GradientBoostingRegressor(max_depth= 2, learning_rate= 0.1, random_state= 10,n_estimators=5000, \n",
    "                                n_iter_no_change = 11))\n",
    "              \n",
    "             ]\n",
    "\n",
    "stack = StackingRegressor(estimators= estimators,\n",
    "                          final_estimator= Ridge(), \n",
    "                          )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJ-r-fafb2Qw",
    "outputId": "aeda3282-b8e9-438e-fd88-dfa36d6c7c1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Score: 0.5762229576080763\n",
      "Standard Deviation: 0.08756604747415982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 12.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 12.2min finished\n"
     ]
    }
   ],
   "source": [
    "cv_score = cross_val_score(stack, x2, y2.ravel(), scoring='r2', cv=10, verbose=5, n_jobs=-1)\n",
    "print('Mean Score:',cv_score.mean())\n",
    "print('Standard Deviation:',cv_score.std())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMlkOYcOb2Qy"
   },
   "source": [
    "## R^2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9n5iukmb2Qy",
    "outputId": "207dd268-bc50-4f37-9169-f6a94638514b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------------------------------+------------------+--------------+---------------+\n",
      "|       MODELS      |                 FEATURES                | CROSS-VALIDATION | PUBLIC SCORE | PRIVATE SCORE |\n",
      "+-------------------+-----------------------------------------+------------------+--------------+---------------+\n",
      "|   DECISION TREE   | TOP FEATURES USING SELECT K BEST METHOD |      0.6018      |   0.54021    |    0.52598    |\n",
      "|   RANDOM FOREST   | TOP FEATURES USING SELECT K BEST METHOD |      0.6435      |   0.54543    |    0.54326    |\n",
      "|      XGBOOST      | TOP FEATURES USING SELECT K BEST METHOD |      0.6100      |   0.54561    |    0.53864    |\n",
      "|     ADA-BOOST     | TOP FEATURES USING SELECT K BEST METHOD |      0.6420      |   0.53577    |    0.53955    |\n",
      "| GRADIENT BOOSTING | TOP FEATURES USING SELECT K BEST METHOD |      0.6409      |   0.53822    |    0.53663    |\n",
      "|     LIGHT GBM     | TOP FEATURES USING SELECT K BEST METHOD |      0.6331      |   0.53822    |    0.54449    |\n",
      "|  STCKED-ENSEMBLE  | TOP FEATURES USING SELECT K BEST METHOD |      0.5762      |   0.55039    |    0.54710    |\n",
      "+-------------------+-----------------------------------------+------------------+--------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "col = ['MODELS', 'FEATURES', 'CROSS-VALIDATION' , 'PUBLIC SCORE', 'PRIVATE SCORE']\n",
    "\n",
    "tb = PrettyTable() \n",
    "\n",
    "tb.add_column(col[0], ['DECISION TREE', 'RANDOM FOREST', 'XGBOOST', 'ADA-BOOST', 'GRADIENT BOOSTING', 'LIGHT GBM', 'STCKED-ENSEMBLE'])\n",
    "\n",
    "tb.add_column(col[1], ['TOP FEATURES USING SELECT K BEST METHOD', 'TOP FEATURES USING SELECT K BEST METHOD', 'TOP FEATURES USING SELECT K BEST METHOD',\n",
    "                       'TOP FEATURES USING SELECT K BEST METHOD', 'TOP FEATURES USING SELECT K BEST METHOD', 'TOP FEATURES USING SELECT K BEST METHOD',\n",
    "                       'TOP FEATURES USING SELECT K BEST METHOD'])\n",
    "\n",
    "tb.add_column(col[2], ['0.6018', '0.6435', '0.6100', '0.6420', '0.6409', '0.6331', '0.5762'])\n",
    "\n",
    "tb.add_column(col[3], ['0.54021', '0.54543', '0.54561', '0.53577', '0.53822', '0.53822', '0.55039'])\n",
    "\n",
    "tb.add_column(col[4], ['0.52598', '0.54326', '0.53864', '0.53955', '0.53663', '0.54449', '0.54710'])\n",
    "\n",
    "print(tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2qqyUYEqhsd"
   },
   "source": [
    "## OBSERVATION\n",
    "\n",
    "\n",
    "\n",
    "*   This dataset created with help of SelectKBest feature selection method, we selected top 250 most important features. But we can see that these features are not get good score than other. \n",
    "*   In this sets stacked ensembles perform best and also another datasets, stacked model got 0.55039 in public and 0.54710 in private leaderboard.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy of Models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
